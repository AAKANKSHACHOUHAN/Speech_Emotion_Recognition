{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "x, sr = librosa.load('/Users/murielkosaka/Desktop/capstone_project/audio/audio_speech_actors_01-24/Actor_01/03-01-01-01-01-01-01.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveplot(x, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Audio(data=x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "single_mfcc = librosa.feature.mfcc(y=x, sr=sr, n_mfcc=13)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(3,1,1)\n",
    "librosa.display.specshow(single_mfcc, x_axis='time')\n",
    "plt.ylabel('MFCC')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole Dataset (1440 files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import glob \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import os # interface with underlying OS that python is running on\n",
    "import sys\n",
    "import warnings\n",
    "# ignore warnings \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "\n",
    "Vocal channel (01 = speech, 02 = song).\n",
    "\n",
    "Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "\n",
    "Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "\n",
    "Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "\n",
    "Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "\n",
    "Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
    "\n",
    "So, here's an example of an audio filename. 02-01-06-01-02-01-12.mp4\n",
    "\n",
    "This means the meta data for the audio file is:\n",
    "\n",
    "Video-only (02)\n",
    "\n",
    "Speech (01)\n",
    "\n",
    "Fearful (06)\n",
    "\n",
    "Normal intensity (01)\n",
    "\n",
    "Statement \"dogs\" (02)\n",
    "\n",
    "1st Repetition (01)\n",
    "\n",
    "12th Actor (12) - Female (as the actor ID number is even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = \"/content/drive/My Drive/audio/audio_speech_actors_01-24/\"\n",
    "actor_folders = os.listdir(audio) #list files in audio directory\n",
    "actor_folders.sort() \n",
    "actor_folders[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find . -name '.DS_Store' -type f -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Actor_01', 'Actor_02', 'Actor_03', 'Actor_04', 'Actor_05']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio = \"/Users/murielkosaka/Desktop/capstone_project/audio/audio_speech_actors_01-24/\"\n",
    "\n",
    "actor_folders = os.listdir(audio) #list files in audio directory\n",
    "actor_folders.sort() \n",
    "actor_folders[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/murielkosaka/Desktop/capstone_project/audio/audio_speech_actors_01-24/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio/audio/audio_speech_actors_01-24/Actor_14\n",
    "# 03-01-02-01-02-01-14.wav\n",
    "\n",
    "emotion = []\n",
    "gender = []\n",
    "file_path = []\n",
    "for i in actor_folders:\n",
    "    filename = os.listdir(audio + i) #iterate over Actor folders\n",
    "    for f in filename: # go through files in Actor folder\n",
    "        part = f.split('.')[0].split('-')\n",
    "        emotion.append(int(part[2]))\n",
    "        bg = int(part[6])\n",
    "        if bg%2 == 0:\n",
    "            bg = \"female\"\n",
    "        else:\n",
    "            bg = \"male\"\n",
    "        gender.append(bg)\n",
    "        file_path.append(audio + i + '/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['03-01-03-02-01-02-24.wav',\n",
       " '03-01-03-01-02-02-24.wav',\n",
       " '03-01-02-02-02-01-24.wav',\n",
       " '03-01-02-01-01-01-24.wav',\n",
       " '03-01-01-01-01-02-24.wav',\n",
       " '03-01-06-01-01-02-24.wav',\n",
       " '03-01-05-01-01-01-24.wav',\n",
       " '03-01-05-02-02-01-24.wav',\n",
       " '03-01-06-02-02-02-24.wav',\n",
       " '03-01-04-01-02-02-24.wav',\n",
       " '03-01-07-01-02-01-24.wav',\n",
       " '03-01-07-02-01-01-24.wav',\n",
       " '03-01-04-02-01-02-24.wav',\n",
       " '03-01-08-02-01-01-24.wav',\n",
       " '03-01-08-01-02-01-24.wav',\n",
       " '03-01-05-01-02-02-24.wav',\n",
       " '03-01-06-01-02-01-24.wav',\n",
       " '03-01-06-02-01-01-24.wav',\n",
       " '03-01-05-02-01-02-24.wav',\n",
       " '03-01-07-01-01-02-24.wav',\n",
       " '03-01-04-01-01-01-24.wav',\n",
       " '03-01-04-02-02-01-24.wav',\n",
       " '03-01-07-02-02-02-24.wav',\n",
       " '03-01-08-02-02-02-24.wav',\n",
       " '03-01-08-01-01-02-24.wav',\n",
       " '03-01-03-02-02-01-24.wav',\n",
       " '03-01-03-01-01-01-24.wav',\n",
       " '03-01-02-02-01-02-24.wav',\n",
       " '03-01-01-01-02-01-24.wav',\n",
       " '03-01-02-01-02-02-24.wav',\n",
       " '03-01-04-02-01-01-24.wav',\n",
       " '03-01-07-02-01-02-24.wav',\n",
       " '03-01-07-01-02-02-24.wav',\n",
       " '03-01-04-01-02-01-24.wav',\n",
       " '03-01-06-02-02-01-24.wav',\n",
       " '03-01-05-02-02-02-24.wav',\n",
       " '03-01-05-01-01-02-24.wav',\n",
       " '03-01-06-01-01-01-24.wav',\n",
       " '03-01-08-01-02-02-24.wav',\n",
       " '03-01-08-02-01-02-24.wav',\n",
       " '03-01-01-01-01-01-24.wav',\n",
       " '03-01-02-01-01-02-24.wav',\n",
       " '03-01-02-02-02-02-24.wav',\n",
       " '03-01-03-01-02-01-24.wav',\n",
       " '03-01-03-02-01-01-24.wav',\n",
       " '03-01-02-01-02-01-24.wav',\n",
       " '03-01-01-01-02-02-24.wav',\n",
       " '03-01-02-02-01-01-24.wav',\n",
       " '03-01-03-01-01-02-24.wav',\n",
       " '03-01-03-02-02-02-24.wav',\n",
       " '03-01-07-02-02-01-24.wav',\n",
       " '03-01-04-02-02-02-24.wav',\n",
       " '03-01-04-01-01-02-24.wav',\n",
       " '03-01-07-01-01-01-24.wav',\n",
       " '03-01-05-02-01-01-24.wav',\n",
       " '03-01-06-02-01-02-24.wav',\n",
       " '03-01-06-01-02-02-24.wav',\n",
       " '03-01-05-01-02-01-24.wav',\n",
       " '03-01-08-01-01-01-24.wav',\n",
       " '03-01-08-02-02-01-24.wav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(audio + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female_fear        96\n",
       "male_sad           96\n",
       "male_calm          96\n",
       "male_surprise      96\n",
       "female_angry       96\n",
       "female_disgust     96\n",
       "male_angry         96\n",
       "female_calm        96\n",
       "female_sad         96\n",
       "male_disgust       96\n",
       "female_surprise    96\n",
       "female_happy       96\n",
       "male_happy         96\n",
       "male_fear          96\n",
       "female_neutral     48\n",
       "male_neutral       48\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_df = pd.DataFrame(emotion)\n",
    "audio_df = audio_df.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\n",
    "audio_df = pd.concat([pd.DataFrame(gender),audio_df],axis=1)\n",
    "audio_df.columns = ['gender','emotion']\n",
    "audio_df['labels'] =audio_df.gender + '_' + audio_df.emotion\n",
    "audio_df = pd.concat([audio_df,pd.DataFrame(file_path, columns = ['path'])],axis=1)\n",
    "audio_df = audio_df.drop(['gender', 'emotion'], axis=1)\n",
    "audio_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df.to_csv('audio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.listdir(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fname = audio + 'Actor_02/03-01-01-01-01-01-02.wav'  #female neutral\n",
    "data_neutral, sr_neutral = librosa.load(fname)\n",
    "plt.figure(figsize=(10, 5))\n",
    "librosa.display.waveplot(data_neutral, sr=sr_neutral)\n",
    "ipd.Audio(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fname = audio + 'Actor_02/03-01-02-01-01-01-02.wav'  #female calm\n",
    "data, sampling_rate = librosa.load(fname)\n",
    "plt.figure(figsize=(10, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)\n",
    "ipd.Audio(fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC\n",
    "### The mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features (usually about 10–20) which concisely describe the overall shape of a spectral envelope. MFCC is a good \"representation\" of the vocal tract that produces the sound. Think of it like an x-ray of your mouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_mfcc = librosa.feature.mfcc(y=data_neutral, sr=sr_neutral, n_mfcc=13)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(3,1,1)\n",
    "librosa.display.specshow(fa_mfcc, x_axis='time')\n",
    "plt.ylabel('MFCC')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCC\n",
    "#The mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features \n",
    "#(usually about 10–20) which concisely describe the overall shape of a spectral envelope.\n",
    "# good \"representation\" of the vocal tract that produces the sound. Think of it like an \n",
    "# x-ray of your mouth\n",
    "mfcc = librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=13)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(3,1,1)\n",
    "librosa.display.specshow(mfcc, x_axis='time')\n",
    "plt.ylabel('MFCC')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male surprised\n",
    "pathh = audio + 'Actor_09/03-01-08-02-02-02-09.wav'\n",
    "X, sample_rate = librosa.load(pathh, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "male = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
    "male = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13), axis=0)\n",
    "print(len(male))\n",
    "\n",
    "# Female surprised\n",
    "path= audio + 'Actor_08/03-01-08-02-02-02-08.wav'\n",
    "X, sample_rate = librosa.load(path,duration=2.5,sr=22050*2,offset=0.5)\n",
    "female = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
    "female = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13), axis=0)\n",
    "print(len(female))\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(female, label='Female Surprised')\n",
    "plt.plot(male, label='Male Surprised')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogram - how the audio spectrum varies as a function of time\n",
    "spectrogram = librosa.feature.melspectrogram(y=X, sr=sampling_rate)\n",
    "db_spec = librosa.power_to_db(spectrogram, ref=np.max,)\n",
    "librosa.display.specshow(db_spec,y_axis='mel', x_axis='time', sr=sampling_rate)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-61.862374191339036, -61.862374191339036, -61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-61.50800105381538, -61.50800105381538, -61.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-55.66308593160217, -56.17033629546251, -56.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-63.52352959684379, -63.52352959684379, -63.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-43.19739053316282, -44.238600301837614, -43....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        mfcc_feature\n",
       "0  [-61.862374191339036, -61.862374191339036, -61...\n",
       "1  [-61.50800105381538, -61.50800105381538, -61.5...\n",
       "2  [-55.66308593160217, -56.17033629546251, -56.1...\n",
       "3  [-63.52352959684379, -63.52352959684379, -63.5...\n",
       "4  [-43.19739053316282, -44.238600301837614, -43...."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['mfcc_feature'])\n",
    "\n",
    "# FEATURE EXTRACTION OVER ENTIRE DATASET\n",
    "counter=0\n",
    "for index,path in enumerate(audio_df.path):\n",
    "    X, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=2.5,sr=44100,offset=0.5)\n",
    "    sample_rate = np.array(sample_rate)\n",
    "    \n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "    df.loc[counter] = [mfccs]\n",
    "    counter=counter+1   \n",
    "\n",
    "\n",
    "print(len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chroma = pd.DataFrame(columns=['chroma_feat'])\n",
    "\n",
    "# feature extraction over the entire dataset\n",
    "counter=0\n",
    "for index,path in enumerate(audio_df.path):\n",
    "    X, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=2.5,sr=44100,offset=0.5)\n",
    "    sample_rate = np.array(sample_rate)\n",
    "    \n",
    "    chroma=np.mean(librosa.feature.chroma_stft(X, sr=sample_rate).T,axis=0)\n",
    "    df_chroma.loc[counter] = [chroma]\n",
    "    counter=counter+1   \n",
    "\n",
    "\n",
    "print(len(df_chroma))\n",
    "df_chroma.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_feature(file_name, mfcc, chroma, mel):\n",
    "#     with soundfile.SoundFile(file_name) as sound_file:\n",
    "#         X = sound_file.read(dtype=\"float32\")\n",
    "#         sample_rate=sound_file.samplerate\n",
    "#         if chroma:\n",
    "#             stft=np.abs(librosa.stft(X))\n",
    "#         result=np.array([])\n",
    "#         if mfcc:\n",
    "#             mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "#             result=np.hstack((result, mfccs))\n",
    "#         if chroma:\n",
    "#             chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "#             result=np.hstack((result, chroma))\n",
    "#         if mel:\n",
    "#             mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "#             result=np.hstack((result, mel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Dense, Embedding, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_chroma' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1e5c6432cec8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# SET MEANS TO THEIR OWN COLUMNS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_combined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudio_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mfcc_feature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_chroma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chroma_feat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_combined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_chroma' is not defined"
     ]
    }
   ],
   "source": [
    "# SET MEANS TO THEIR OWN COLUMNS\n",
    "\n",
    "df_combined = pd.concat([audio_df,pd.DataFrame(df['mfcc_feature'].values.tolist()),pd.DataFrame(df_chroma['chroma_feat'].values.tolist())],axis=1)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SET MEANS TO THEIR OWN COLUMNS\n",
    "df = pd.concat([audio_df,pd.DataFrame(df['mfcc_feature'].values.tolist())],axis=1)\n",
    "df=df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>-38.602824</td>\n",
       "      <td>-38.376867</td>\n",
       "      <td>-40.069538</td>\n",
       "      <td>-41.195162</td>\n",
       "      <td>-42.362900</td>\n",
       "      <td>-44.729526</td>\n",
       "      <td>-45.260184</td>\n",
       "      <td>-47.097828</td>\n",
       "      <td>-47.518257</td>\n",
       "      <td>-46.041445</td>\n",
       "      <td>...</td>\n",
       "      <td>-46.052606</td>\n",
       "      <td>-45.207639</td>\n",
       "      <td>-43.329992</td>\n",
       "      <td>-44.557592</td>\n",
       "      <td>-44.176429</td>\n",
       "      <td>-44.633846</td>\n",
       "      <td>-45.570087</td>\n",
       "      <td>-44.207098</td>\n",
       "      <td>-44.271797</td>\n",
       "      <td>-43.716439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>-45.079425</td>\n",
       "      <td>-45.182942</td>\n",
       "      <td>-45.832742</td>\n",
       "      <td>-45.270958</td>\n",
       "      <td>-44.004987</td>\n",
       "      <td>-43.305987</td>\n",
       "      <td>-43.619046</td>\n",
       "      <td>-44.168447</td>\n",
       "      <td>-45.227714</td>\n",
       "      <td>-46.027550</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.230139</td>\n",
       "      <td>-34.175652</td>\n",
       "      <td>-34.334331</td>\n",
       "      <td>-35.172133</td>\n",
       "      <td>-36.398492</td>\n",
       "      <td>-33.733008</td>\n",
       "      <td>-32.789335</td>\n",
       "      <td>-31.659165</td>\n",
       "      <td>-24.270392</td>\n",
       "      <td>-19.262934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>-55.940431</td>\n",
       "      <td>-53.966883</td>\n",
       "      <td>-48.489172</td>\n",
       "      <td>-46.202820</td>\n",
       "      <td>-48.171796</td>\n",
       "      <td>-52.160146</td>\n",
       "      <td>-53.075813</td>\n",
       "      <td>-51.588053</td>\n",
       "      <td>-51.635007</td>\n",
       "      <td>-54.397662</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.294194</td>\n",
       "      <td>-50.708138</td>\n",
       "      <td>-51.764476</td>\n",
       "      <td>-50.936385</td>\n",
       "      <td>-51.729512</td>\n",
       "      <td>-55.929644</td>\n",
       "      <td>-56.014049</td>\n",
       "      <td>-54.965400</td>\n",
       "      <td>-54.467538</td>\n",
       "      <td>-56.980523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>-65.210437</td>\n",
       "      <td>-65.210437</td>\n",
       "      <td>-65.210437</td>\n",
       "      <td>-65.210437</td>\n",
       "      <td>-65.210437</td>\n",
       "      <td>-65.210437</td>\n",
       "      <td>-65.210437</td>\n",
       "      <td>-65.210437</td>\n",
       "      <td>-65.210437</td>\n",
       "      <td>-65.210437</td>\n",
       "      <td>...</td>\n",
       "      <td>-55.057056</td>\n",
       "      <td>-52.671282</td>\n",
       "      <td>-53.739885</td>\n",
       "      <td>-56.870101</td>\n",
       "      <td>-58.528605</td>\n",
       "      <td>-61.192075</td>\n",
       "      <td>-57.778604</td>\n",
       "      <td>-58.670580</td>\n",
       "      <td>-62.437393</td>\n",
       "      <td>-65.043140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>-63.728967</td>\n",
       "      <td>-63.728967</td>\n",
       "      <td>-63.728967</td>\n",
       "      <td>-63.728967</td>\n",
       "      <td>-63.728967</td>\n",
       "      <td>-63.728967</td>\n",
       "      <td>-63.728967</td>\n",
       "      <td>-63.728967</td>\n",
       "      <td>-63.728967</td>\n",
       "      <td>-63.728967</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.142724</td>\n",
       "      <td>-23.274047</td>\n",
       "      <td>-23.532521</td>\n",
       "      <td>-24.240024</td>\n",
       "      <td>-25.887856</td>\n",
       "      <td>-26.925746</td>\n",
       "      <td>-26.725288</td>\n",
       "      <td>-27.133949</td>\n",
       "      <td>-28.466279</td>\n",
       "      <td>-29.287304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>-63.488734</td>\n",
       "      <td>-60.576644</td>\n",
       "      <td>-56.701765</td>\n",
       "      <td>-56.070490</td>\n",
       "      <td>-58.910577</td>\n",
       "      <td>-61.154979</td>\n",
       "      <td>-59.071259</td>\n",
       "      <td>-56.579099</td>\n",
       "      <td>-55.198979</td>\n",
       "      <td>-56.515550</td>\n",
       "      <td>...</td>\n",
       "      <td>-60.204609</td>\n",
       "      <td>-59.535544</td>\n",
       "      <td>-55.875539</td>\n",
       "      <td>-54.532013</td>\n",
       "      <td>-55.293654</td>\n",
       "      <td>-55.092284</td>\n",
       "      <td>-54.403174</td>\n",
       "      <td>-56.776214</td>\n",
       "      <td>-59.719546</td>\n",
       "      <td>-60.744719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>-52.120092</td>\n",
       "      <td>-51.624869</td>\n",
       "      <td>-49.452746</td>\n",
       "      <td>-47.018253</td>\n",
       "      <td>-42.051262</td>\n",
       "      <td>-38.245040</td>\n",
       "      <td>-36.825672</td>\n",
       "      <td>-36.134838</td>\n",
       "      <td>-36.307171</td>\n",
       "      <td>-36.386367</td>\n",
       "      <td>...</td>\n",
       "      <td>-52.064366</td>\n",
       "      <td>-51.343363</td>\n",
       "      <td>-50.900494</td>\n",
       "      <td>-49.770724</td>\n",
       "      <td>-49.436901</td>\n",
       "      <td>-49.256986</td>\n",
       "      <td>-49.062109</td>\n",
       "      <td>-48.616749</td>\n",
       "      <td>-45.257563</td>\n",
       "      <td>-41.612494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>-56.569065</td>\n",
       "      <td>-59.373479</td>\n",
       "      <td>-61.183981</td>\n",
       "      <td>-58.684713</td>\n",
       "      <td>-59.174422</td>\n",
       "      <td>-58.193958</td>\n",
       "      <td>-58.287371</td>\n",
       "      <td>-58.266463</td>\n",
       "      <td>-58.675418</td>\n",
       "      <td>-57.727294</td>\n",
       "      <td>...</td>\n",
       "      <td>-45.402751</td>\n",
       "      <td>-44.373086</td>\n",
       "      <td>-43.040298</td>\n",
       "      <td>-43.771453</td>\n",
       "      <td>-45.011255</td>\n",
       "      <td>-48.073412</td>\n",
       "      <td>-49.772008</td>\n",
       "      <td>-49.812591</td>\n",
       "      <td>-50.470094</td>\n",
       "      <td>-57.511489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>...</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.490429</td>\n",
       "      <td>-64.711893</td>\n",
       "      <td>-64.748927</td>\n",
       "      <td>-64.647586</td>\n",
       "      <td>-64.494358</td>\n",
       "      <td>-64.790254</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-73.841370</td>\n",
       "      <td>-73.841370</td>\n",
       "      <td>-73.841370</td>\n",
       "      <td>-73.719655</td>\n",
       "      <td>-73.841370</td>\n",
       "      <td>-73.841370</td>\n",
       "      <td>-73.841370</td>\n",
       "      <td>-73.303635</td>\n",
       "      <td>-72.806811</td>\n",
       "      <td>-73.841370</td>\n",
       "      <td>...</td>\n",
       "      <td>-51.629344</td>\n",
       "      <td>-50.568866</td>\n",
       "      <td>-53.505840</td>\n",
       "      <td>-54.222252</td>\n",
       "      <td>-51.545521</td>\n",
       "      <td>-52.573785</td>\n",
       "      <td>-54.786292</td>\n",
       "      <td>-56.344280</td>\n",
       "      <td>-57.508212</td>\n",
       "      <td>-56.577322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5    \\\n",
       "1050 -38.602824 -38.376867 -40.069538 -41.195162 -42.362900 -44.729526   \n",
       "1089 -45.079425 -45.182942 -45.832742 -45.270958 -44.004987 -43.305987   \n",
       "1272 -55.940431 -53.966883 -48.489172 -46.202820 -48.171796 -52.160146   \n",
       "1029 -65.210437 -65.210437 -65.210437 -65.210437 -65.210437 -65.210437   \n",
       "1336 -63.728967 -63.728967 -63.728967 -63.728967 -63.728967 -63.728967   \n",
       "328  -63.488734 -60.576644 -56.701765 -56.070490 -58.910577 -61.154979   \n",
       "318  -52.120092 -51.624869 -49.452746 -47.018253 -42.051262 -38.245040   \n",
       "1108 -56.569065 -59.373479 -61.183981 -58.684713 -59.174422 -58.193958   \n",
       "1176 -64.974577 -64.974577 -64.974577 -64.974577 -64.974577 -64.974577   \n",
       "12   -73.841370 -73.841370 -73.841370 -73.719655 -73.841370 -73.841370   \n",
       "\n",
       "            6          7          8          9    ...        206        207  \\\n",
       "1050 -45.260184 -47.097828 -47.518257 -46.041445  ... -46.052606 -45.207639   \n",
       "1089 -43.619046 -44.168447 -45.227714 -46.027550  ... -34.230139 -34.175652   \n",
       "1272 -53.075813 -51.588053 -51.635007 -54.397662  ... -50.294194 -50.708138   \n",
       "1029 -65.210437 -65.210437 -65.210437 -65.210437  ... -55.057056 -52.671282   \n",
       "1336 -63.728967 -63.728967 -63.728967 -63.728967  ... -23.142724 -23.274047   \n",
       "328  -59.071259 -56.579099 -55.198979 -56.515550  ... -60.204609 -59.535544   \n",
       "318  -36.825672 -36.134838 -36.307171 -36.386367  ... -52.064366 -51.343363   \n",
       "1108 -58.287371 -58.266463 -58.675418 -57.727294  ... -45.402751 -44.373086   \n",
       "1176 -64.974577 -64.974577 -64.974577 -64.974577  ... -64.974577 -64.490429   \n",
       "12   -73.841370 -73.303635 -72.806811 -73.841370  ... -51.629344 -50.568866   \n",
       "\n",
       "            208        209        210        211        212        213  \\\n",
       "1050 -43.329992 -44.557592 -44.176429 -44.633846 -45.570087 -44.207098   \n",
       "1089 -34.334331 -35.172133 -36.398492 -33.733008 -32.789335 -31.659165   \n",
       "1272 -51.764476 -50.936385 -51.729512 -55.929644 -56.014049 -54.965400   \n",
       "1029 -53.739885 -56.870101 -58.528605 -61.192075 -57.778604 -58.670580   \n",
       "1336 -23.532521 -24.240024 -25.887856 -26.925746 -26.725288 -27.133949   \n",
       "328  -55.875539 -54.532013 -55.293654 -55.092284 -54.403174 -56.776214   \n",
       "318  -50.900494 -49.770724 -49.436901 -49.256986 -49.062109 -48.616749   \n",
       "1108 -43.040298 -43.771453 -45.011255 -48.073412 -49.772008 -49.812591   \n",
       "1176 -64.711893 -64.748927 -64.647586 -64.494358 -64.790254 -64.974577   \n",
       "12   -53.505840 -54.222252 -51.545521 -52.573785 -54.786292 -56.344280   \n",
       "\n",
       "            214        215  \n",
       "1050 -44.271797 -43.716439  \n",
       "1089 -24.270392 -19.262934  \n",
       "1272 -54.467538 -56.980523  \n",
       "1029 -62.437393 -65.043140  \n",
       "1336 -28.466279 -29.287304  \n",
       "328  -59.719546 -60.744719  \n",
       "318  -45.257563 -41.612494  \n",
       "1108 -50.470094 -57.511489  \n",
       "1176 -64.974577 -64.974577  \n",
       "12   -57.508212 -56.577322  \n",
       "\n",
       "[10 rows x 216 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN TEST SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['path','labels'],axis=1)\n",
    "                                                    , df.labels\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=42\n",
    "                                                   )\n",
    "\n",
    "X_train[150:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>2.043785</td>\n",
       "      <td>2.076431</td>\n",
       "      <td>1.889681</td>\n",
       "      <td>1.744563</td>\n",
       "      <td>1.590705</td>\n",
       "      <td>1.296221</td>\n",
       "      <td>1.211334</td>\n",
       "      <td>0.986006</td>\n",
       "      <td>0.930114</td>\n",
       "      <td>1.098861</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028600</td>\n",
       "      <td>0.066520</td>\n",
       "      <td>0.246526</td>\n",
       "      <td>0.165557</td>\n",
       "      <td>0.212588</td>\n",
       "      <td>0.192907</td>\n",
       "      <td>0.138659</td>\n",
       "      <td>0.277094</td>\n",
       "      <td>0.193460</td>\n",
       "      <td>0.182777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>1.272987</td>\n",
       "      <td>1.254305</td>\n",
       "      <td>1.187352</td>\n",
       "      <td>1.249924</td>\n",
       "      <td>1.392449</td>\n",
       "      <td>1.467846</td>\n",
       "      <td>1.406848</td>\n",
       "      <td>1.333665</td>\n",
       "      <td>1.202422</td>\n",
       "      <td>1.100510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987896</td>\n",
       "      <td>1.014428</td>\n",
       "      <td>1.015379</td>\n",
       "      <td>0.969520</td>\n",
       "      <td>0.877493</td>\n",
       "      <td>1.130017</td>\n",
       "      <td>1.236822</td>\n",
       "      <td>1.350468</td>\n",
       "      <td>1.741182</td>\n",
       "      <td>1.898229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>-0.019610</td>\n",
       "      <td>0.193268</td>\n",
       "      <td>0.863628</td>\n",
       "      <td>1.136834</td>\n",
       "      <td>0.889372</td>\n",
       "      <td>0.400371</td>\n",
       "      <td>0.280236</td>\n",
       "      <td>0.453107</td>\n",
       "      <td>0.440701</td>\n",
       "      <td>0.106931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.393291</td>\n",
       "      <td>-0.406102</td>\n",
       "      <td>-0.474363</td>\n",
       "      <td>-0.380853</td>\n",
       "      <td>-0.433095</td>\n",
       "      <td>-0.778156</td>\n",
       "      <td>-0.758720</td>\n",
       "      <td>-0.643192</td>\n",
       "      <td>-0.595494</td>\n",
       "      <td>-0.747719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>-1.122858</td>\n",
       "      <td>-1.164874</td>\n",
       "      <td>-1.174098</td>\n",
       "      <td>-1.169930</td>\n",
       "      <td>-1.167775</td>\n",
       "      <td>-1.172998</td>\n",
       "      <td>-1.165396</td>\n",
       "      <td>-1.163597</td>\n",
       "      <td>-1.173193</td>\n",
       "      <td>-1.176606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.802802</td>\n",
       "      <td>-0.574783</td>\n",
       "      <td>-0.643200</td>\n",
       "      <td>-0.889137</td>\n",
       "      <td>-1.014323</td>\n",
       "      <td>-1.230550</td>\n",
       "      <td>-0.910336</td>\n",
       "      <td>-0.960141</td>\n",
       "      <td>-1.212206</td>\n",
       "      <td>-1.313324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>-0.946544</td>\n",
       "      <td>-0.985923</td>\n",
       "      <td>-0.993560</td>\n",
       "      <td>-0.990139</td>\n",
       "      <td>-0.988911</td>\n",
       "      <td>-0.994389</td>\n",
       "      <td>-0.988904</td>\n",
       "      <td>-0.987777</td>\n",
       "      <td>-0.997071</td>\n",
       "      <td>-1.000747</td>\n",
       "      <td>...</td>\n",
       "      <td>1.941192</td>\n",
       "      <td>1.951132</td>\n",
       "      <td>1.938602</td>\n",
       "      <td>1.905968</td>\n",
       "      <td>1.776006</td>\n",
       "      <td>1.715215</td>\n",
       "      <td>1.757864</td>\n",
       "      <td>1.737564</td>\n",
       "      <td>1.416501</td>\n",
       "      <td>1.195004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>-0.917953</td>\n",
       "      <td>-0.605144</td>\n",
       "      <td>-0.137194</td>\n",
       "      <td>-0.060706</td>\n",
       "      <td>-0.407166</td>\n",
       "      <td>-0.684064</td>\n",
       "      <td>-0.434018</td>\n",
       "      <td>-0.139230</td>\n",
       "      <td>0.017004</td>\n",
       "      <td>-0.144474</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.245389</td>\n",
       "      <td>-1.164585</td>\n",
       "      <td>-0.825733</td>\n",
       "      <td>-0.688855</td>\n",
       "      <td>-0.737780</td>\n",
       "      <td>-0.706170</td>\n",
       "      <td>-0.620309</td>\n",
       "      <td>-0.798093</td>\n",
       "      <td>-1.001898</td>\n",
       "      <td>-1.011783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.435059</td>\n",
       "      <td>0.476166</td>\n",
       "      <td>0.746202</td>\n",
       "      <td>1.037873</td>\n",
       "      <td>1.628331</td>\n",
       "      <td>2.078003</td>\n",
       "      <td>2.216161</td>\n",
       "      <td>2.287094</td>\n",
       "      <td>2.262927</td>\n",
       "      <td>2.244973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.545491</td>\n",
       "      <td>-0.460683</td>\n",
       "      <td>-0.400519</td>\n",
       "      <td>-0.281002</td>\n",
       "      <td>-0.237109</td>\n",
       "      <td>-0.204529</td>\n",
       "      <td>-0.161387</td>\n",
       "      <td>-0.100116</td>\n",
       "      <td>0.117180</td>\n",
       "      <td>0.330372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>-0.094425</td>\n",
       "      <td>-0.459811</td>\n",
       "      <td>-0.683417</td>\n",
       "      <td>-0.377968</td>\n",
       "      <td>-0.439021</td>\n",
       "      <td>-0.327077</td>\n",
       "      <td>-0.340632</td>\n",
       "      <td>-0.339487</td>\n",
       "      <td>-0.396287</td>\n",
       "      <td>-0.288315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027275</td>\n",
       "      <td>0.138228</td>\n",
       "      <td>0.271286</td>\n",
       "      <td>0.232898</td>\n",
       "      <td>0.141222</td>\n",
       "      <td>-0.102781</td>\n",
       "      <td>-0.222384</td>\n",
       "      <td>-0.202411</td>\n",
       "      <td>-0.286169</td>\n",
       "      <td>-0.784967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>-1.094787</td>\n",
       "      <td>-1.136384</td>\n",
       "      <td>-1.145355</td>\n",
       "      <td>-1.141306</td>\n",
       "      <td>-1.139299</td>\n",
       "      <td>-1.144562</td>\n",
       "      <td>-1.137297</td>\n",
       "      <td>-1.135605</td>\n",
       "      <td>-1.145153</td>\n",
       "      <td>-1.148608</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.655511</td>\n",
       "      <td>-1.590326</td>\n",
       "      <td>-1.580970</td>\n",
       "      <td>-1.564040</td>\n",
       "      <td>-1.537410</td>\n",
       "      <td>-1.514436</td>\n",
       "      <td>-1.512800</td>\n",
       "      <td>-1.499397</td>\n",
       "      <td>-1.408535</td>\n",
       "      <td>-1.308514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-2.150048</td>\n",
       "      <td>-2.207429</td>\n",
       "      <td>-2.225901</td>\n",
       "      <td>-2.202608</td>\n",
       "      <td>-2.209824</td>\n",
       "      <td>-2.213560</td>\n",
       "      <td>-2.193623</td>\n",
       "      <td>-2.124098</td>\n",
       "      <td>-2.076276</td>\n",
       "      <td>-2.201146</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508088</td>\n",
       "      <td>-0.394136</td>\n",
       "      <td>-0.623196</td>\n",
       "      <td>-0.662321</td>\n",
       "      <td>-0.417366</td>\n",
       "      <td>-0.489663</td>\n",
       "      <td>-0.653227</td>\n",
       "      <td>-0.761144</td>\n",
       "      <td>-0.830783</td>\n",
       "      <td>-0.719434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "1050  2.043785  2.076431  1.889681  1.744563  1.590705  1.296221  1.211334   \n",
       "1089  1.272987  1.254305  1.187352  1.249924  1.392449  1.467846  1.406848   \n",
       "1272 -0.019610  0.193268  0.863628  1.136834  0.889372  0.400371  0.280236   \n",
       "1029 -1.122858 -1.164874 -1.174098 -1.169930 -1.167775 -1.172998 -1.165396   \n",
       "1336 -0.946544 -0.985923 -0.993560 -0.990139 -0.988911 -0.994389 -0.988904   \n",
       "328  -0.917953 -0.605144 -0.137194 -0.060706 -0.407166 -0.684064 -0.434018   \n",
       "318   0.435059  0.476166  0.746202  1.037873  1.628331  2.078003  2.216161   \n",
       "1108 -0.094425 -0.459811 -0.683417 -0.377968 -0.439021 -0.327077 -0.340632   \n",
       "1176 -1.094787 -1.136384 -1.145355 -1.141306 -1.139299 -1.144562 -1.137297   \n",
       "12   -2.150048 -2.207429 -2.225901 -2.202608 -2.209824 -2.213560 -2.193623   \n",
       "\n",
       "           7         8         9    ...       206       207       208  \\\n",
       "1050  0.986006  0.930114  1.098861  ... -0.028600  0.066520  0.246526   \n",
       "1089  1.333665  1.202422  1.100510  ...  0.987896  1.014428  1.015379   \n",
       "1272  0.453107  0.440701  0.106931  ... -0.393291 -0.406102 -0.474363   \n",
       "1029 -1.163597 -1.173193 -1.176606  ... -0.802802 -0.574783 -0.643200   \n",
       "1336 -0.987777 -0.997071 -1.000747  ...  1.941192  1.951132  1.938602   \n",
       "328  -0.139230  0.017004 -0.144474  ... -1.245389 -1.164585 -0.825733   \n",
       "318   2.287094  2.262927  2.244973  ... -0.545491 -0.460683 -0.400519   \n",
       "1108 -0.339487 -0.396287 -0.288315  ...  0.027275  0.138228  0.271286   \n",
       "1176 -1.135605 -1.145153 -1.148608  ... -1.655511 -1.590326 -1.580970   \n",
       "12   -2.124098 -2.076276 -2.201146  ... -0.508088 -0.394136 -0.623196   \n",
       "\n",
       "           209       210       211       212       213       214       215  \n",
       "1050  0.165557  0.212588  0.192907  0.138659  0.277094  0.193460  0.182777  \n",
       "1089  0.969520  0.877493  1.130017  1.236822  1.350468  1.741182  1.898229  \n",
       "1272 -0.380853 -0.433095 -0.778156 -0.758720 -0.643192 -0.595494 -0.747719  \n",
       "1029 -0.889137 -1.014323 -1.230550 -0.910336 -0.960141 -1.212206 -1.313324  \n",
       "1336  1.905968  1.776006  1.715215  1.757864  1.737564  1.416501  1.195004  \n",
       "328  -0.688855 -0.737780 -0.706170 -0.620309 -0.798093 -1.001898 -1.011783  \n",
       "318  -0.281002 -0.237109 -0.204529 -0.161387 -0.100116  0.117180  0.330372  \n",
       "1108  0.232898  0.141222 -0.102781 -0.222384 -0.202411 -0.286169 -0.784967  \n",
       "1176 -1.564040 -1.537410 -1.514436 -1.512800 -1.499397 -1.408535 -1.308514  \n",
       "12   -0.662321 -0.417366 -0.489663 -0.653227 -0.761144 -0.830783 -0.719434  \n",
       "\n",
       "[10 rows x 216 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NORMALIZE DATA\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std\n",
    "\n",
    "X_train[150:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TURN DATA INTO ARRAYS FOR KERAS\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['male_angry', 'male_sad', 'female_fear', 'female_disgust',\n",
       "       'male_happy', 'male_angry', 'female_disgust', 'female_calm',\n",
       "       'female_calm', 'male_happy', 'female_happy', 'female_calm',\n",
       "       'male_fear', 'female_fear', 'male_sad', 'female_sad',\n",
       "       'female_angry', 'male_angry', 'female_surprise', 'female_surprise',\n",
       "       'female_sad', 'female_calm', 'female_surprise', 'male_fear',\n",
       "       'female_angry', 'male_happy', 'male_disgust', 'male_disgust',\n",
       "       'male_fear', 'male_angry', 'male_angry', 'male_fear', 'male_happy',\n",
       "       'male_disgust', 'male_neutral', 'male_disgust', 'male_disgust',\n",
       "       'male_disgust', 'female_happy', 'male_sad', 'female_sad',\n",
       "       'male_neutral', 'female_calm', 'male_sad', 'male_sad',\n",
       "       'male_surprise', 'female_sad', 'male_calm', 'female_angry',\n",
       "       'female_angry', 'male_calm', 'female_angry', 'male_happy',\n",
       "       'female_calm', 'female_calm', 'female_surprise', 'female_fear',\n",
       "       'female_fear', 'male_happy', 'male_sad', 'male_fear',\n",
       "       'female_surprise', 'male_neutral', 'female_fear', 'female_calm',\n",
       "       'female_fear', 'female_happy', 'male_angry', 'female_disgust',\n",
       "       'male_angry', 'female_happy', 'female_fear', 'female_angry',\n",
       "       'female_happy', 'male_sad', 'male_fear', 'male_calm',\n",
       "       'female_calm', 'male_angry', 'female_calm', 'male_sad',\n",
       "       'female_neutral', 'female_fear', 'male_sad', 'female_neutral',\n",
       "       'male_surprise', 'female_calm', 'female_happy', 'male_happy',\n",
       "       'female_disgust', 'female_happy', 'female_neutral',\n",
       "       'female_neutral', 'female_disgust', 'female_sad', 'male_surprise',\n",
       "       'male_sad', 'male_calm', 'female_sad', 'male_happy',\n",
       "       'female_happy', 'male_happy', 'male_disgust', 'male_disgust',\n",
       "       'male_surprise', 'female_surprise', 'female_angry', 'female_sad',\n",
       "       'male_disgust', 'male_happy', 'female_sad', 'female_calm',\n",
       "       'female_calm', 'male_fear', 'female_sad', 'female_happy',\n",
       "       'male_happy', 'male_fear', 'male_surprise', 'male_disgust',\n",
       "       'female_disgust', 'female_disgust', 'female_neutral', 'male_fear',\n",
       "       'male_angry', 'male_happy', 'female_calm', 'male_calm',\n",
       "       'female_angry', 'female_happy', 'male_calm', 'male_happy',\n",
       "       'male_fear', 'male_fear', 'female_disgust', 'male_sad',\n",
       "       'female_angry', 'male_sad', 'female_disgust', 'female_calm',\n",
       "       'male_angry', 'female_surprise', 'female_disgust', 'male_fear',\n",
       "       'male_calm', 'male_surprise', 'male_disgust', 'male_calm',\n",
       "       'male_happy', 'female_angry', 'male_surprise', 'female_disgust',\n",
       "       'female_calm', 'male_surprise', 'female_happy', 'male_surprise',\n",
       "       'female_disgust', 'male_angry', 'male_happy', 'female_surprise',\n",
       "       'male_disgust', 'male_fear', 'female_fear', 'female_sad',\n",
       "       'female_surprise', 'female_fear', 'male_sad', 'female_calm',\n",
       "       'female_surprise', 'female_sad', 'female_sad', 'male_angry',\n",
       "       'female_angry', 'female_fear', 'male_fear', 'female_disgust',\n",
       "       'male_calm', 'male_calm', 'male_happy', 'female_angry',\n",
       "       'female_calm', 'female_calm', 'female_calm', 'female_sad',\n",
       "       'female_surprise', 'male_happy', 'female_disgust', 'female_fear',\n",
       "       'female_sad', 'male_neutral', 'male_surprise', 'female_fear',\n",
       "       'female_happy', 'female_angry', 'male_angry', 'female_surprise',\n",
       "       'male_calm', 'female_surprise', 'female_surprise',\n",
       "       'female_surprise', 'female_happy', 'male_fear', 'male_happy',\n",
       "       'female_disgust', 'male_happy', 'female_sad', 'male_neutral',\n",
       "       'female_disgust', 'male_calm', 'male_angry', 'female_sad',\n",
       "       'male_surprise', 'female_sad', 'female_happy', 'female_calm',\n",
       "       'male_angry', 'female_calm', 'female_neutral', 'female_surprise',\n",
       "       'male_happy', 'female_disgust', 'male_fear', 'female_neutral',\n",
       "       'female_surprise', 'male_angry', 'female_sad', 'female_fear',\n",
       "       'female_angry', 'male_sad', 'male_angry', 'female_surprise',\n",
       "       'female_fear', 'female_sad', 'male_neutral', 'female_surprise',\n",
       "       'female_sad', 'female_surprise', 'male_disgust', 'female_disgust',\n",
       "       'male_calm', 'male_calm', 'male_angry', 'female_sad', 'male_calm',\n",
       "       'male_sad', 'female_angry', 'male_sad', 'male_surprise',\n",
       "       'male_sad', 'female_fear', 'male_happy', 'male_disgust',\n",
       "       'male_angry', 'male_happy', 'male_calm', 'female_fear',\n",
       "       'male_disgust', 'female_disgust', 'female_sad', 'male_sad',\n",
       "       'male_surprise', 'female_sad', 'female_disgust', 'female_surprise',\n",
       "       'male_happy', 'male_happy', 'female_happy', 'female_happy',\n",
       "       'female_neutral', 'male_surprise', 'female_calm', 'male_calm',\n",
       "       'male_angry', 'male_surprise', 'male_neutral', 'male_fear',\n",
       "       'male_surprise', 'male_surprise', 'female_sad', 'male_sad',\n",
       "       'female_neutral', 'female_neutral', 'female_sad', 'male_angry',\n",
       "       'male_neutral', 'female_calm', 'male_neutral', 'male_sad',\n",
       "       'female_angry', 'female_sad', 'female_neutral', 'female_surprise',\n",
       "       'male_fear', 'female_happy', 'male_surprise', 'female_neutral',\n",
       "       'female_happy', 'female_fear', 'female_happy', 'female_sad',\n",
       "       'male_disgust', 'male_fear', 'female_fear', 'male_neutral',\n",
       "       'female_disgust', 'male_fear', 'female_happy', 'male_sad',\n",
       "       'female_sad', 'female_surprise', 'female_angry', 'female_fear',\n",
       "       'female_surprise', 'female_calm', 'female_fear', 'female_angry',\n",
       "       'male_disgust', 'male_fear', 'male_happy', 'male_sad',\n",
       "       'female_sad', 'male_angry', 'female_angry', 'male_angry',\n",
       "       'female_angry', 'male_calm', 'male_angry', 'female_happy',\n",
       "       'female_sad', 'male_calm', 'male_sad', 'male_fear',\n",
       "       'female_neutral', 'male_angry', 'female_neutral', 'female_happy',\n",
       "       'male_sad', 'female_happy', 'male_happy', 'male_angry',\n",
       "       'male_angry', 'female_calm', 'female_disgust', 'female_surprise',\n",
       "       'male_angry', 'female_surprise', 'female_neutral', 'female_calm',\n",
       "       'male_fear', 'female_sad', 'male_angry', 'female_angry',\n",
       "       'male_sad', 'female_angry', 'male_fear', 'female_angry',\n",
       "       'male_sad', 'male_disgust', 'female_happy', 'female_sad'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# ONE HOT ENCODE THE TARGET\n",
    "# CNN REQUIRES INPUT AND OUTPUT ARE NUMBERS\n",
    "lb = LabelEncoder()\n",
    "y_train = to_categorical(lb.fit_transform(y_train))\n",
    "y_test = to_categorical(lb.fit_transform(y_test))\n",
    "print(y_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female_angry' 'female_calm' 'female_disgust' 'female_fear'\n",
      " 'female_happy' 'female_neutral' 'female_sad' 'female_surprise'\n",
      " 'male_angry' 'male_calm' 'male_disgust' 'male_fear' 'male_happy'\n",
      " 'male_neutral' 'male_sad' 'male_surprise']\n"
     ]
    }
   ],
   "source": [
    "print(lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 216, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#time series data requires kernel sliding in only one dimension and have spatial properties: 1d CNN\n",
    "# reshape data to 3d tensor\n",
    "X_train = X_train[:,:,np.newaxis]\n",
    "X_test = X_test[:,:,np.newaxis]\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 216, 64)           576       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 216, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 216, 64)           32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 216, 64)           256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 216, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 27, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 27, 128)           65664     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 27, 128)           131200    \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 27, 128)           131200    \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 27, 128)           131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 27, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 3, 256)            262400    \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 3, 256)            524544    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                12304     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 1,292,688\n",
      "Trainable params: 1,292,304\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "#BUILD CNN MODEL\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 8, padding='same',input_shape=(X_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(64, 8, padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 8, padding='same',activation='relu'))\n",
    "model.add(Conv1D(128, 8, padding='same',activation='relu'))\n",
    "model.add(Conv1D(128, 8, padding='same',activation='relu'))\n",
    "model.add(Conv1D(128, 8, padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(256, 8, padding='same',activation='relu'))\n",
    "model.add(Conv1D(256, 8, padding='same',activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16)) # Target class number\n",
    "model.add(Activation('softmax'))\n",
    "# opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n",
    "opt = keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1080 samples, validate on 360 samples\n",
      "Epoch 1/50\n",
      "1080/1080 [==============================] - 6s 6ms/step - loss: 2.7420 - acc: 0.0880 - val_loss: 2.6453 - val_acc: 0.1528\n",
      "Epoch 2/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 2.5594 - acc: 0.1657 - val_loss: 2.5401 - val_acc: 0.2000\n",
      "Epoch 3/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 2.4556 - acc: 0.2185 - val_loss: 2.4596 - val_acc: 0.2139\n",
      "Epoch 4/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 2.3730 - acc: 0.2259 - val_loss: 2.4054 - val_acc: 0.2333\n",
      "Epoch 5/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 2.2915 - acc: 0.2648 - val_loss: 2.3519 - val_acc: 0.2472\n",
      "Epoch 6/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 2.2099 - acc: 0.3037 - val_loss: 2.3058 - val_acc: 0.2583\n",
      "Epoch 7/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 2.1681 - acc: 0.2880 - val_loss: 2.2641 - val_acc: 0.2722\n",
      "Epoch 8/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 2.0939 - acc: 0.3222 - val_loss: 2.2290 - val_acc: 0.2750\n",
      "Epoch 9/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 2.0643 - acc: 0.3269 - val_loss: 2.1986 - val_acc: 0.2917\n",
      "Epoch 10/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 2.0221 - acc: 0.3370 - val_loss: 2.1693 - val_acc: 0.2917\n",
      "Epoch 11/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 1.9658 - acc: 0.3454 - val_loss: 2.1395 - val_acc: 0.2722\n",
      "Epoch 12/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 1.9263 - acc: 0.3750 - val_loss: 2.1113 - val_acc: 0.2972\n",
      "Epoch 13/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 1.8775 - acc: 0.3750 - val_loss: 2.0858 - val_acc: 0.3056\n",
      "Epoch 14/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 1.8358 - acc: 0.3981 - val_loss: 2.0593 - val_acc: 0.3056\n",
      "Epoch 15/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 1.8109 - acc: 0.4148 - val_loss: 2.0374 - val_acc: 0.3167\n",
      "Epoch 16/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 1.7540 - acc: 0.4370 - val_loss: 2.0066 - val_acc: 0.3194\n",
      "Epoch 17/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 1.7206 - acc: 0.4333 - val_loss: 1.9978 - val_acc: 0.3250\n",
      "Epoch 18/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 1.7062 - acc: 0.4454 - val_loss: 1.9690 - val_acc: 0.3333\n",
      "Epoch 19/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 1.6833 - acc: 0.4528 - val_loss: 1.9554 - val_acc: 0.3250\n",
      "Epoch 20/50\n",
      "1080/1080 [==============================] - 8s 7ms/step - loss: 1.6352 - acc: 0.4676 - val_loss: 1.9377 - val_acc: 0.3444\n",
      "Epoch 21/50\n",
      "1080/1080 [==============================] - 6s 6ms/step - loss: 1.5986 - acc: 0.4861 - val_loss: 1.9209 - val_acc: 0.3361\n",
      "Epoch 22/50\n",
      "1080/1080 [==============================] - 7s 6ms/step - loss: 1.5732 - acc: 0.4769 - val_loss: 1.9068 - val_acc: 0.3306\n",
      "Epoch 23/50\n",
      "1080/1080 [==============================] - 6s 5ms/step - loss: 1.5632 - acc: 0.4852 - val_loss: 1.9078 - val_acc: 0.3250\n",
      "Epoch 24/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 1.5139 - acc: 0.5074 - val_loss: 1.8817 - val_acc: 0.3500\n",
      "Epoch 25/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 1.4863 - acc: 0.5296 - val_loss: 1.8655 - val_acc: 0.3528\n",
      "Epoch 26/50\n",
      "1080/1080 [==============================] - 6s 5ms/step - loss: 1.4610 - acc: 0.5278 - val_loss: 1.8577 - val_acc: 0.3583\n",
      "Epoch 27/50\n",
      "1080/1080 [==============================] - 6s 5ms/step - loss: 1.4201 - acc: 0.5574 - val_loss: 1.8489 - val_acc: 0.3611\n",
      "Epoch 28/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 1.3965 - acc: 0.5509 - val_loss: 1.8500 - val_acc: 0.3556\n",
      "Epoch 29/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 1.3545 - acc: 0.5907 - val_loss: 1.8334 - val_acc: 0.3750\n",
      "Epoch 30/50\n",
      "1080/1080 [==============================] - 6s 5ms/step - loss: 1.3504 - acc: 0.5750 - val_loss: 1.8178 - val_acc: 0.3778\n",
      "Epoch 31/50\n",
      "1080/1080 [==============================] - 6s 5ms/step - loss: 1.3153 - acc: 0.5898 - val_loss: 1.8197 - val_acc: 0.3611\n",
      "Epoch 32/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 1.2852 - acc: 0.6028 - val_loss: 1.7995 - val_acc: 0.3833\n",
      "Epoch 33/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 1.2507 - acc: 0.6204 - val_loss: 1.7882 - val_acc: 0.3833\n",
      "Epoch 34/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 1.2472 - acc: 0.6213 - val_loss: 1.7820 - val_acc: 0.3861\n",
      "Epoch 35/50\n",
      "1080/1080 [==============================] - 6s 5ms/step - loss: 1.1980 - acc: 0.6352 - val_loss: 1.7680 - val_acc: 0.4000\n",
      "Epoch 36/50\n",
      "1080/1080 [==============================] - 6s 6ms/step - loss: 1.2043 - acc: 0.6194 - val_loss: 1.7808 - val_acc: 0.3917\n",
      "Epoch 37/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 1.1671 - acc: 0.6556 - val_loss: 1.7670 - val_acc: 0.4028\n",
      "Epoch 38/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 1.1216 - acc: 0.6556 - val_loss: 1.7432 - val_acc: 0.4000\n",
      "Epoch 39/50\n",
      "1080/1080 [==============================] - 6s 5ms/step - loss: 1.1149 - acc: 0.6824 - val_loss: 1.7514 - val_acc: 0.3917\n",
      "Epoch 40/50\n",
      "1080/1080 [==============================] - 7s 6ms/step - loss: 1.0901 - acc: 0.6704 - val_loss: 1.7480 - val_acc: 0.3778\n",
      "Epoch 41/50\n",
      "1080/1080 [==============================] - 6s 5ms/step - loss: 1.0561 - acc: 0.6815 - val_loss: 1.7411 - val_acc: 0.3917\n",
      "Epoch 42/50\n",
      "1080/1080 [==============================] - 6s 5ms/step - loss: 1.0406 - acc: 0.7213 - val_loss: 1.7626 - val_acc: 0.3778\n",
      "Epoch 43/50\n",
      "1080/1080 [==============================] - 6s 5ms/step - loss: 1.0311 - acc: 0.6944 - val_loss: 1.7553 - val_acc: 0.3861\n",
      "Epoch 44/50\n",
      "1080/1080 [==============================] - 5s 5ms/step - loss: 0.9690 - acc: 0.7185 - val_loss: 1.7436 - val_acc: 0.3917\n",
      "Epoch 45/50\n",
      "1080/1080 [==============================] - 6s 5ms/step - loss: 0.9701 - acc: 0.7352 - val_loss: 1.7358 - val_acc: 0.3917\n",
      "Epoch 46/50\n",
      "1080/1080 [==============================] - 7s 6ms/step - loss: 0.9609 - acc: 0.7296 - val_loss: 1.7127 - val_acc: 0.3972\n",
      "Epoch 47/50\n",
      "1080/1080 [==============================] - 6s 6ms/step - loss: 0.8949 - acc: 0.7574 - val_loss: 1.7203 - val_acc: 0.4000\n",
      "Epoch 48/50\n",
      "1080/1080 [==============================] - 6s 5ms/step - loss: 0.8953 - acc: 0.7481 - val_loss: 1.7313 - val_acc: 0.3889\n",
      "Epoch 49/50\n",
      "1080/1080 [==============================] - 6s 5ms/step - loss: 0.8501 - acc: 0.7648 - val_loss: 1.7251 - val_acc: 0.4083\n",
      "Epoch 50/50\n",
      "1080/1080 [==============================] - 6s 5ms/step - loss: 0.8672 - acc: 0.7537 - val_loss: 1.6981 - val_acc: 0.4056\n"
     ]
    }
   ],
   "source": [
    "# FIT MODEL\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model_history=model.fit(X_train, y_train,batch_size=16, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 0s 1ms/step\n",
      "Loss of the model is -  1.6981058677037557\n",
      "360/360 [==============================] - 0s 920us/step\n",
      "Accuracy of the model is -  40.55555555555556 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss of the model is - \" , model.evaluate(X_test,y_test)[0])\n",
    "print(\"Accuracy of the model is - \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 epoch\n",
    "# val_accuracy = .3972 mfcc\n",
    "    # .3722 mfcc\n",
    "# val_accuracy = 0.2139 chroma\n",
    "# val_accuracy = 0.0639 mfcc + chroma\n",
    "# 50 epoch - changed random_state\n",
    "# val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-926ff759d50c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = [i for i in range(12)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = model_history.history['accuracy']\n",
    "train_loss = model_history.history['loss']\n",
    "val_acc = model_history.history['val_accuracy']\n",
    "val_loss = model_history.history['val_loss']\n",
    "fig.set_size_inches(20,10)\n",
    "\n",
    "ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\n",
    "ax[0].plot(epochs , val_acc , 'ro-' , label = 'Validation Accuracy')\n",
    "ax[0].set_title('Training & Validation Accuracy')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\n",
    "ax[1].plot(epochs , val_loss , 'r-o' , label = 'Validation Loss')\n",
    "ax[1].set_title('Testing Accuracy & Loss')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"Training & Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_piczak.drop(['esc'],axis=1)\n",
    "Y = df_piczak['esc']\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranfom forest on MFCC features\n",
    "rfc_mfcc = RandomForestClassifier(n_estimators=1000, max_depth=None, min_samples_split=2,n_jobs=-1, random_state=42)\n",
    "rfc_mfcc.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the mean bands to its own feature columns\n",
    "df = pd.concat([audio_df,pd.DataFrame(df['mfcc_feature'].values.tolist())],axis=1)\n",
    "df=df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split between train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['path','labels'],axis=1)\n",
    "                                                    , df.labels\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=22\n",
    "                                                   )\n",
    "\n",
    "# Lets see how the data present itself before normalisation \n",
    "X_train[150:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MLPClassifier(alpha=0.01, batch_size=216,epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#DataFlair - Calculate the accuracy of our model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "#DataFlair - Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split between train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['path','labels'],axis=1)\n",
    "                                                    , df.labels\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=22\n",
    "                                                   )\n",
    "\n",
    "# Lets see how the data present itself before normalisation \n",
    "X_train[150:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "# random forest model creation\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "# predictions\n",
    "rfc_predict = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_cv_score = cross_val_score(rfc, X, y, cv=10, scoring=’roc_auc’)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# number of features at every split\n",
    "max_features = [‘auto’, ‘sqrt’]\n",
    "\n",
    "# max depth\n",
    "max_depth = [int(x) for x in np.linspace(100, 500, num = 11)]\n",
    "max_depth.append(None)\n",
    "# create random grid\n",
    "random_grid = {\n",
    " ‘n_estimators’: n_estimators,\n",
    " ‘max_features’: max_features,\n",
    " ‘max_depth’: max_depth\n",
    " }\n",
    "# Random search of parameters\n",
    "rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the model\n",
    "rfc_random.fit(X_train, y_train)\n",
    "# print results\n",
    "print(rfc_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing data\n",
    "train_data = pd.DataFrame()\n",
    "train_data['fname'] = train['fname']\n",
    "test_data = pd.DataFrame()\n",
    "test_data['fname'] = audio_test_files\n",
    "\n",
    "train_data = train_data['fname'].apply(get_mfcc, path='../input/audio_train/')\n",
    "print('done loading train mfcc')\n",
    "test_data = test_data['fname'].apply(get_mfcc, path='../input/audio_test/')\n",
    "print('done loading test mfcc')\n",
    "\n",
    "train_data['label'] = train['label']\n",
    "test_data['label'] = np.zeros((len(audio_test_files)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
