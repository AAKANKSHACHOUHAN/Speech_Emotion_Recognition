{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "x, sr = librosa.load('/Users/murielkosaka/Desktop/capstone_project/audio/audio_speech_actors_01-24/Actor_01/03-01-01-01-01-01-01.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveplot(x, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Audio(data=x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "single_mfcc = librosa.feature.mfcc(y=x, sr=sr, n_mfcc=13)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(3,1,1)\n",
    "librosa.display.specshow(single_mfcc, x_axis='time')\n",
    "plt.ylabel('MFCC')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole Dataset (1440 files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import glob \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import os # interface with underlying OS that python is running on\n",
    "import sys\n",
    "import warnings\n",
    "# ignore warnings \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "\n",
    "Vocal channel (01 = speech, 02 = song).\n",
    "\n",
    "Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "\n",
    "Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "\n",
    "Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "\n",
    "Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "\n",
    "Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
    "\n",
    "So, here's an example of an audio filename. 02-01-06-01-02-01-12.mp4\n",
    "\n",
    "This means the meta data for the audio file is:\n",
    "\n",
    "Video-only (02)\n",
    "\n",
    "Speech (01)\n",
    "\n",
    "Fearful (06)\n",
    "\n",
    "Normal intensity (01)\n",
    "\n",
    "Statement \"dogs\" (02)\n",
    "\n",
    "1st Repetition (01)\n",
    "\n",
    "12th Actor (12) - Female (as the actor ID number is even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m.\u001b[m\u001b[m/                       .gitignore               audio.csv\r\n",
      "\u001b[34m..\u001b[m\u001b[m/                      \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m/      eda_preprocessing.ipynb\r\n",
      ".DS_Store                README.md\r\n",
      "\u001b[34m.git\u001b[m\u001b[m/                    \u001b[34maudio\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find . -name '.DS_Store' -type f -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Actor_01', 'Actor_02', 'Actor_03', 'Actor_04', 'Actor_05']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio = \"/Users/murielkosaka/Desktop/capstone_project/audio/audio_speech_actors_01-24/\"\n",
    "\n",
    "actor_folders = os.listdir(audio) #list files in audio directory\n",
    "actor_folders.sort() \n",
    "actor_folders[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/murielkosaka/Desktop/capstone_project/audio/audio_speech_actors_01-24/'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio/audio/audio_speech_actors_01-24/Actor_14\n",
    "# 03-01-02-01-02-01-14.wav\n",
    "\n",
    "emotion = []\n",
    "gender = []\n",
    "file_path = []\n",
    "for i in actor_folders:\n",
    "    filename = os.listdir(audio + i) #iterate over Actor folders\n",
    "    for f in filename: # go through files in Actor folder\n",
    "        part = f.split('.')[0].split('-')\n",
    "        emotion.append(int(part[2]))\n",
    "        bg = int(part[6])\n",
    "        if bg%2 == 0:\n",
    "            bg = \"female\"\n",
    "        else:\n",
    "            bg = \"male\"\n",
    "        gender.append(bg)\n",
    "        file_path.append(audio + i + '/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['03-01-03-02-01-02-24.wav',\n",
       " '03-01-03-01-02-02-24.wav',\n",
       " '03-01-02-02-02-01-24.wav',\n",
       " '03-01-02-01-01-01-24.wav',\n",
       " '03-01-01-01-01-02-24.wav',\n",
       " '03-01-06-01-01-02-24.wav',\n",
       " '03-01-05-01-01-01-24.wav',\n",
       " '03-01-05-02-02-01-24.wav',\n",
       " '03-01-06-02-02-02-24.wav',\n",
       " '03-01-04-01-02-02-24.wav',\n",
       " '03-01-07-01-02-01-24.wav',\n",
       " '03-01-07-02-01-01-24.wav',\n",
       " '03-01-04-02-01-02-24.wav',\n",
       " '03-01-08-02-01-01-24.wav',\n",
       " '03-01-08-01-02-01-24.wav',\n",
       " '03-01-05-01-02-02-24.wav',\n",
       " '03-01-06-01-02-01-24.wav',\n",
       " '03-01-06-02-01-01-24.wav',\n",
       " '03-01-05-02-01-02-24.wav',\n",
       " '03-01-07-01-01-02-24.wav',\n",
       " '03-01-04-01-01-01-24.wav',\n",
       " '03-01-04-02-02-01-24.wav',\n",
       " '03-01-07-02-02-02-24.wav',\n",
       " '03-01-08-02-02-02-24.wav',\n",
       " '03-01-08-01-01-02-24.wav',\n",
       " '03-01-03-02-02-01-24.wav',\n",
       " '03-01-03-01-01-01-24.wav',\n",
       " '03-01-02-02-01-02-24.wav',\n",
       " '03-01-01-01-02-01-24.wav',\n",
       " '03-01-02-01-02-02-24.wav',\n",
       " '03-01-04-02-01-01-24.wav',\n",
       " '03-01-07-02-01-02-24.wav',\n",
       " '03-01-07-01-02-02-24.wav',\n",
       " '03-01-04-01-02-01-24.wav',\n",
       " '03-01-06-02-02-01-24.wav',\n",
       " '03-01-05-02-02-02-24.wav',\n",
       " '03-01-05-01-01-02-24.wav',\n",
       " '03-01-06-01-01-01-24.wav',\n",
       " '03-01-08-01-02-02-24.wav',\n",
       " '03-01-08-02-01-02-24.wav',\n",
       " '03-01-01-01-01-01-24.wav',\n",
       " '03-01-02-01-01-02-24.wav',\n",
       " '03-01-02-02-02-02-24.wav',\n",
       " '03-01-03-01-02-01-24.wav',\n",
       " '03-01-03-02-01-01-24.wav',\n",
       " '03-01-02-01-02-01-24.wav',\n",
       " '03-01-01-01-02-02-24.wav',\n",
       " '03-01-02-02-01-01-24.wav',\n",
       " '03-01-03-01-01-02-24.wav',\n",
       " '03-01-03-02-02-02-24.wav',\n",
       " '03-01-07-02-02-01-24.wav',\n",
       " '03-01-04-02-02-02-24.wav',\n",
       " '03-01-04-01-01-02-24.wav',\n",
       " '03-01-07-01-01-01-24.wav',\n",
       " '03-01-05-02-01-01-24.wav',\n",
       " '03-01-06-02-01-02-24.wav',\n",
       " '03-01-06-01-02-02-24.wav',\n",
       " '03-01-05-01-02-01-24.wav',\n",
       " '03-01-08-01-01-01-24.wav',\n",
       " '03-01-08-02-02-01-24.wav']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(audio + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male_surprise      96\n",
       "female_happy       96\n",
       "female_disgust     96\n",
       "male_fear          96\n",
       "male_disgust       96\n",
       "female_angry       96\n",
       "female_surprise    96\n",
       "female_calm        96\n",
       "male_calm          96\n",
       "male_angry         96\n",
       "female_sad         96\n",
       "female_fear        96\n",
       "male_happy         96\n",
       "male_sad           96\n",
       "female_neutral     48\n",
       "male_neutral       48\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_df = pd.DataFrame(emotion)\n",
    "audio_df = audio_df.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\n",
    "audio_df = pd.concat([pd.DataFrame(gender),audio_df],axis=1)\n",
    "audio_df.columns = ['gender','emotion']\n",
    "audio_df['labels'] =audio_df.gender + '_' + audio_df.emotion\n",
    "audio_df = pd.concat([audio_df,pd.DataFrame(file_path, columns = ['path'])],axis=1)\n",
    "audio_df = audio_df.drop(['gender', 'emotion'], axis=1)\n",
    "audio_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df.to_csv('audio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.listdir(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fname = audio + 'Actor_02/03-01-01-01-01-01-02.wav'  #female neutral\n",
    "data_neutral, sr_neutral = librosa.load(fname)\n",
    "plt.figure(figsize=(10, 5))\n",
    "librosa.display.waveplot(data_neutral, sr=sr_neutral)\n",
    "ipd.Audio(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fname = audio + 'Actor_02/03-01-02-01-01-01-02.wav'  #female calm\n",
    "data, sampling_rate = librosa.load(fname)\n",
    "plt.figure(figsize=(10, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)\n",
    "ipd.Audio(fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC\n",
    "### The mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features (usually about 10–20) which concisely describe the overall shape of a spectral envelope. MFCC is a good \"representation\" of the vocal tract that produces the sound. Think of it like an x-ray of your mouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_mfcc = librosa.feature.mfcc(y=data_neutral, sr=sr_neutral, n_mfcc=13)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(3,1,1)\n",
    "librosa.display.specshow(fa_mfcc, x_axis='time')\n",
    "plt.ylabel('MFCC')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCC\n",
    "#The mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features \n",
    "#(usually about 10–20) which concisely describe the overall shape of a spectral envelope.\n",
    "# good \"representation\" of the vocal tract that produces the sound. Think of it like an \n",
    "# x-ray of your mouth\n",
    "mfcc = librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=13)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(3,1,1)\n",
    "librosa.display.specshow(mfcc, x_axis='time')\n",
    "plt.ylabel('MFCC')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male surprised\n",
    "pathh = audio + 'Actor_09/03-01-08-02-02-02-09.wav'\n",
    "X, sample_rate = librosa.load(pathh, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "male = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
    "male = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13), axis=0)\n",
    "print(len(male))\n",
    "\n",
    "# Female surprised\n",
    "path= audio + 'Actor_08/03-01-08-02-02-02-08.wav'\n",
    "X, sample_rate = librosa.load(path,duration=2.5,sr=22050*2,offset=0.5)\n",
    "female = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
    "female = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13), axis=0)\n",
    "print(len(female))\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(female, label='Female Surprised')\n",
    "plt.plot(male, label='Male Surprised')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogram - how the audio spectrum varies as a function of time\n",
    "spectrogram = librosa.feature.melspectrogram(y=X, sr=sampling_rate)\n",
    "db_spec = librosa.power_to_db(spectrogram, ref=np.max,)\n",
    "librosa.display.specshow(db_spec,y_axis='mel', x_axis='time', sr=sampling_rate)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-61.862374191339036, -61.862374191339036, -61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-61.50800105381538, -61.50800105381538, -61.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-55.66308593160217, -56.17033629546251, -56.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-63.52352959684379, -63.52352959684379, -63.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-43.19739053316282, -44.238600301837614, -43....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        mfcc_feature\n",
       "0  [-61.862374191339036, -61.862374191339036, -61...\n",
       "1  [-61.50800105381538, -61.50800105381538, -61.5...\n",
       "2  [-55.66308593160217, -56.17033629546251, -56.1...\n",
       "3  [-63.52352959684379, -63.52352959684379, -63.5...\n",
       "4  [-43.19739053316282, -44.238600301837614, -43...."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['mfcc_feature'])\n",
    "\n",
    "# feature extraction over the entire dataset\n",
    "counter=0\n",
    "for index,path in enumerate(audio_df.path):\n",
    "    X, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=2.5,sr=44100,offset=0.5)\n",
    "    sample_rate = np.array(sample_rate)\n",
    "    \n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "    df.loc[counter] = [mfccs]\n",
    "    counter=counter+1   \n",
    "\n",
    "\n",
    "print(len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chroma = pd.DataFrame(columns=['chroma_feat'])\n",
    "\n",
    "# feature extraction over the entire dataset\n",
    "counter=0\n",
    "for index,path in enumerate(audio_df.path):\n",
    "    X, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=2.5,sr=44100,offset=0.5)\n",
    "    sample_rate = np.array(sample_rate)\n",
    "    \n",
    "    chroma=np.mean(librosa.feature.chroma_stft(X, sr=sample_rate).T,axis=0)\n",
    "    df_chroma.loc[counter] = [chroma]\n",
    "    counter=counter+1   \n",
    "\n",
    "\n",
    "print(len(df_chroma))\n",
    "df_chroma.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract the mean bands to its own feature columns\n",
    "df_combined = pd.concat([audio_df,pd.DataFrame(df['mfcc_feature'].values.tolist()),pd.DataFrame(df_chroma['chroma_feat'].values.tolist())],axis=1)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mfcc_feature'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mfcc_feature'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0609f93b731e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Extract the mean bands to its own feature columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudio_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mfcc_feature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mfcc_feature'"
     ]
    }
   ],
   "source": [
    "# Extract the mean bands to its own feature columns\n",
    "df = pd.concat([audio_df,pd.DataFrame(df['mfcc_feature'].values.tolist())],axis=1)\n",
    "df=df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>-38.602824</td>\n",
       "      <td>-38.376867</td>\n",
       "      <td>-40.069538</td>\n",
       "      <td>-41.195162</td>\n",
       "      <td>-42.362900</td>\n",
       "      <td>-44.729526</td>\n",
       "      <td>-45.260184</td>\n",
       "      <td>-47.097828</td>\n",
       "      <td>-47.518257</td>\n",
       "      <td>-46.041445</td>\n",
       "      <td>...</td>\n",
       "      <td>-46.052606</td>\n",
       "      <td>-45.207639</td>\n",
       "      <td>-43.329992</td>\n",
       "      <td>-44.557592</td>\n",
       "      <td>-44.176429</td>\n",
       "      <td>-44.633846</td>\n",
       "      <td>-45.570087</td>\n",
       "      <td>-44.207098</td>\n",
       "      <td>-44.271797</td>\n",
       "      <td>-43.716439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>-45.079425</td>\n",
       "      <td>-45.182942</td>\n",
       "      <td>-45.832742</td>\n",
       "      <td>-45.270958</td>\n",
       "      <td>-44.004987</td>\n",
       "      <td>-43.305987</td>\n",
       "      <td>-43.619046</td>\n",
       "      <td>-44.168447</td>\n",
       "      <td>-45.227714</td>\n",
       "      <td>-46.027550</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.230139</td>\n",
       "      <td>-34.175652</td>\n",
       "      <td>-34.334331</td>\n",
       "      <td>-35.172133</td>\n",
       "      <td>-36.398492</td>\n",
       "      <td>-33.733008</td>\n",
       "      <td>-32.789335</td>\n",
       "      <td>-31.659165</td>\n",
       "      <td>-24.270392</td>\n",
       "      <td>-19.262934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>-55.940431</td>\n",
       "      <td>-53.966883</td>\n",
       "      <td>-48.489172</td>\n",
       "      <td>-46.202820</td>\n",
       "      <td>-48.171796</td>\n",
       "      <td>-52.160146</td>\n",
       "      <td>-53.075813</td>\n",
       "      <td>-51.588053</td>\n",
       "      <td>-51.635007</td>\n",
       "      <td>-54.397662</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.294194</td>\n",
       "      <td>-50.708138</td>\n",
       "      <td>-51.764476</td>\n",
       "      <td>-50.936385</td>\n",
       "      <td>-51.729512</td>\n",
       "      <td>-55.929644</td>\n",
       "      <td>-56.014049</td>\n",
       "      <td>-54.965400</td>\n",
       "      <td>-54.467538</td>\n",
       "      <td>-56.980523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>-65.210437</td>\n",
       "      <td>-65.210437</td>\n",
       "      <td>-65.210437</td>\n",
       "      <td>-65.210437</td>\n",
       "      <td>-65.210437</td>\n",
       "      <td>-65.210437</td>\n",
       "      <td>-65.210437</td>\n",
       "      <td>-65.210437</td>\n",
       "      <td>-65.210437</td>\n",
       "      <td>-65.210437</td>\n",
       "      <td>...</td>\n",
       "      <td>-55.057056</td>\n",
       "      <td>-52.671282</td>\n",
       "      <td>-53.739885</td>\n",
       "      <td>-56.870101</td>\n",
       "      <td>-58.528605</td>\n",
       "      <td>-61.192075</td>\n",
       "      <td>-57.778604</td>\n",
       "      <td>-58.670580</td>\n",
       "      <td>-62.437393</td>\n",
       "      <td>-65.043140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>-63.728967</td>\n",
       "      <td>-63.728967</td>\n",
       "      <td>-63.728967</td>\n",
       "      <td>-63.728967</td>\n",
       "      <td>-63.728967</td>\n",
       "      <td>-63.728967</td>\n",
       "      <td>-63.728967</td>\n",
       "      <td>-63.728967</td>\n",
       "      <td>-63.728967</td>\n",
       "      <td>-63.728967</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.142724</td>\n",
       "      <td>-23.274047</td>\n",
       "      <td>-23.532521</td>\n",
       "      <td>-24.240024</td>\n",
       "      <td>-25.887856</td>\n",
       "      <td>-26.925746</td>\n",
       "      <td>-26.725288</td>\n",
       "      <td>-27.133949</td>\n",
       "      <td>-28.466279</td>\n",
       "      <td>-29.287304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>-63.488734</td>\n",
       "      <td>-60.576644</td>\n",
       "      <td>-56.701765</td>\n",
       "      <td>-56.070490</td>\n",
       "      <td>-58.910577</td>\n",
       "      <td>-61.154979</td>\n",
       "      <td>-59.071259</td>\n",
       "      <td>-56.579099</td>\n",
       "      <td>-55.198979</td>\n",
       "      <td>-56.515550</td>\n",
       "      <td>...</td>\n",
       "      <td>-60.204609</td>\n",
       "      <td>-59.535544</td>\n",
       "      <td>-55.875539</td>\n",
       "      <td>-54.532013</td>\n",
       "      <td>-55.293654</td>\n",
       "      <td>-55.092284</td>\n",
       "      <td>-54.403174</td>\n",
       "      <td>-56.776214</td>\n",
       "      <td>-59.719546</td>\n",
       "      <td>-60.744719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>-52.120092</td>\n",
       "      <td>-51.624869</td>\n",
       "      <td>-49.452746</td>\n",
       "      <td>-47.018253</td>\n",
       "      <td>-42.051262</td>\n",
       "      <td>-38.245040</td>\n",
       "      <td>-36.825672</td>\n",
       "      <td>-36.134838</td>\n",
       "      <td>-36.307171</td>\n",
       "      <td>-36.386367</td>\n",
       "      <td>...</td>\n",
       "      <td>-52.064366</td>\n",
       "      <td>-51.343363</td>\n",
       "      <td>-50.900494</td>\n",
       "      <td>-49.770724</td>\n",
       "      <td>-49.436901</td>\n",
       "      <td>-49.256986</td>\n",
       "      <td>-49.062109</td>\n",
       "      <td>-48.616749</td>\n",
       "      <td>-45.257563</td>\n",
       "      <td>-41.612494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>-56.569065</td>\n",
       "      <td>-59.373479</td>\n",
       "      <td>-61.183981</td>\n",
       "      <td>-58.684713</td>\n",
       "      <td>-59.174422</td>\n",
       "      <td>-58.193958</td>\n",
       "      <td>-58.287371</td>\n",
       "      <td>-58.266463</td>\n",
       "      <td>-58.675418</td>\n",
       "      <td>-57.727294</td>\n",
       "      <td>...</td>\n",
       "      <td>-45.402751</td>\n",
       "      <td>-44.373086</td>\n",
       "      <td>-43.040298</td>\n",
       "      <td>-43.771453</td>\n",
       "      <td>-45.011255</td>\n",
       "      <td>-48.073412</td>\n",
       "      <td>-49.772008</td>\n",
       "      <td>-49.812591</td>\n",
       "      <td>-50.470094</td>\n",
       "      <td>-57.511489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>...</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.490429</td>\n",
       "      <td>-64.711893</td>\n",
       "      <td>-64.748927</td>\n",
       "      <td>-64.647586</td>\n",
       "      <td>-64.494358</td>\n",
       "      <td>-64.790254</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "      <td>-64.974577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-73.841370</td>\n",
       "      <td>-73.841370</td>\n",
       "      <td>-73.841370</td>\n",
       "      <td>-73.719655</td>\n",
       "      <td>-73.841370</td>\n",
       "      <td>-73.841370</td>\n",
       "      <td>-73.841370</td>\n",
       "      <td>-73.303635</td>\n",
       "      <td>-72.806811</td>\n",
       "      <td>-73.841370</td>\n",
       "      <td>...</td>\n",
       "      <td>-51.629344</td>\n",
       "      <td>-50.568866</td>\n",
       "      <td>-53.505840</td>\n",
       "      <td>-54.222252</td>\n",
       "      <td>-51.545521</td>\n",
       "      <td>-52.573785</td>\n",
       "      <td>-54.786292</td>\n",
       "      <td>-56.344280</td>\n",
       "      <td>-57.508212</td>\n",
       "      <td>-56.577322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5    \\\n",
       "1050 -38.602824 -38.376867 -40.069538 -41.195162 -42.362900 -44.729526   \n",
       "1089 -45.079425 -45.182942 -45.832742 -45.270958 -44.004987 -43.305987   \n",
       "1272 -55.940431 -53.966883 -48.489172 -46.202820 -48.171796 -52.160146   \n",
       "1029 -65.210437 -65.210437 -65.210437 -65.210437 -65.210437 -65.210437   \n",
       "1336 -63.728967 -63.728967 -63.728967 -63.728967 -63.728967 -63.728967   \n",
       "328  -63.488734 -60.576644 -56.701765 -56.070490 -58.910577 -61.154979   \n",
       "318  -52.120092 -51.624869 -49.452746 -47.018253 -42.051262 -38.245040   \n",
       "1108 -56.569065 -59.373479 -61.183981 -58.684713 -59.174422 -58.193958   \n",
       "1176 -64.974577 -64.974577 -64.974577 -64.974577 -64.974577 -64.974577   \n",
       "12   -73.841370 -73.841370 -73.841370 -73.719655 -73.841370 -73.841370   \n",
       "\n",
       "            6          7          8          9    ...        206        207  \\\n",
       "1050 -45.260184 -47.097828 -47.518257 -46.041445  ... -46.052606 -45.207639   \n",
       "1089 -43.619046 -44.168447 -45.227714 -46.027550  ... -34.230139 -34.175652   \n",
       "1272 -53.075813 -51.588053 -51.635007 -54.397662  ... -50.294194 -50.708138   \n",
       "1029 -65.210437 -65.210437 -65.210437 -65.210437  ... -55.057056 -52.671282   \n",
       "1336 -63.728967 -63.728967 -63.728967 -63.728967  ... -23.142724 -23.274047   \n",
       "328  -59.071259 -56.579099 -55.198979 -56.515550  ... -60.204609 -59.535544   \n",
       "318  -36.825672 -36.134838 -36.307171 -36.386367  ... -52.064366 -51.343363   \n",
       "1108 -58.287371 -58.266463 -58.675418 -57.727294  ... -45.402751 -44.373086   \n",
       "1176 -64.974577 -64.974577 -64.974577 -64.974577  ... -64.974577 -64.490429   \n",
       "12   -73.841370 -73.303635 -72.806811 -73.841370  ... -51.629344 -50.568866   \n",
       "\n",
       "            208        209        210        211        212        213  \\\n",
       "1050 -43.329992 -44.557592 -44.176429 -44.633846 -45.570087 -44.207098   \n",
       "1089 -34.334331 -35.172133 -36.398492 -33.733008 -32.789335 -31.659165   \n",
       "1272 -51.764476 -50.936385 -51.729512 -55.929644 -56.014049 -54.965400   \n",
       "1029 -53.739885 -56.870101 -58.528605 -61.192075 -57.778604 -58.670580   \n",
       "1336 -23.532521 -24.240024 -25.887856 -26.925746 -26.725288 -27.133949   \n",
       "328  -55.875539 -54.532013 -55.293654 -55.092284 -54.403174 -56.776214   \n",
       "318  -50.900494 -49.770724 -49.436901 -49.256986 -49.062109 -48.616749   \n",
       "1108 -43.040298 -43.771453 -45.011255 -48.073412 -49.772008 -49.812591   \n",
       "1176 -64.711893 -64.748927 -64.647586 -64.494358 -64.790254 -64.974577   \n",
       "12   -53.505840 -54.222252 -51.545521 -52.573785 -54.786292 -56.344280   \n",
       "\n",
       "            214        215  \n",
       "1050 -44.271797 -43.716439  \n",
       "1089 -24.270392 -19.262934  \n",
       "1272 -54.467538 -56.980523  \n",
       "1029 -62.437393 -65.043140  \n",
       "1336 -28.466279 -29.287304  \n",
       "328  -59.719546 -60.744719  \n",
       "318  -45.257563 -41.612494  \n",
       "1108 -50.470094 -57.511489  \n",
       "1176 -64.974577 -64.974577  \n",
       "12   -57.508212 -56.577322  \n",
       "\n",
       "[10 rows x 216 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split between train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['path','labels'],axis=1)\n",
    "                                                    , df.labels\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=42\n",
    "                                                   )\n",
    "\n",
    "# Lets see how the data present itself before normalisation \n",
    "X_train[150:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets few preparation steps to get it into the correct format for Keras \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils, to_categorical\n",
    "\n",
    "# one hot encode the target \n",
    "lb = LabelEncoder()\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female_angry' 'female_calm' 'female_disgust' 'female_fear'\n",
      " 'female_happy' 'female_neutral' 'female_sad' 'female_surprise'\n",
      " 'male_angry' 'male_calm' 'male_disgust' 'male_fear' 'male_happy'\n",
      " 'male_neutral' 'male_sad' 'male_surprise']\n"
     ]
    }
   ],
   "source": [
    "print(lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reshape() takes exactly 1 argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a67481c3a0ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: reshape() takes exactly 1 argument (0 given)"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape()\n",
    "X_test = X_test.reshape()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 216, 256)          2304      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 216, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 216, 256)          524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 216, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 216, 256)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 216, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 216, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 216, 128)          262272    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 216, 128)          131200    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 216, 128)          131200    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 216, 128)          131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 216, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 216, 64)           65600     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 216, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 216, 64)           32832     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 216, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                221200    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 1,503,888\n",
      "Trainable params: 1,503,120\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "\n",
    "# New model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(256, 8, padding='same',input_shape=(X_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(256, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(1)))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(1)))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16)) # Target class number\n",
    "model.add(Activation('softmax'))\n",
    "# opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1080 samples, validate on 360 samples\n",
      "Epoch 1/50\n",
      "1080/1080 [==============================] - 33s 30ms/step - loss: 2.7866 - acc: 0.1028 - val_loss: 2.6579 - val_acc: 0.1389\n",
      "Epoch 2/50\n",
      "1080/1080 [==============================] - 32s 29ms/step - loss: 2.6150 - acc: 0.1324 - val_loss: 2.5140 - val_acc: 0.1861\n",
      "Epoch 3/50\n",
      "1080/1080 [==============================] - 32s 29ms/step - loss: 2.4716 - acc: 0.1787 - val_loss: 2.4175 - val_acc: 0.2333\n",
      "Epoch 4/50\n",
      "1080/1080 [==============================] - 32s 29ms/step - loss: 2.3742 - acc: 0.2056 - val_loss: 2.3190 - val_acc: 0.2278\n",
      "Epoch 5/50\n",
      "1080/1080 [==============================] - 32s 29ms/step - loss: 2.2715 - acc: 0.2370 - val_loss: 2.2258 - val_acc: 0.2639\n",
      "Epoch 6/50\n",
      "1080/1080 [==============================] - 33s 30ms/step - loss: 2.2049 - acc: 0.2519 - val_loss: 2.1665 - val_acc: 0.2444\n",
      "Epoch 7/50\n",
      "1080/1080 [==============================] - 32s 29ms/step - loss: 2.1676 - acc: 0.2602 - val_loss: 2.1039 - val_acc: 0.2806\n",
      "Epoch 8/50\n",
      "1080/1080 [==============================] - 33s 30ms/step - loss: 2.1202 - acc: 0.2815 - val_loss: 2.0518 - val_acc: 0.3139\n",
      "Epoch 9/50\n",
      "1080/1080 [==============================] - 46s 42ms/step - loss: 2.1088 - acc: 0.2639 - val_loss: 2.0341 - val_acc: 0.2806\n",
      "Epoch 10/50\n",
      "1080/1080 [==============================] - 45s 42ms/step - loss: 2.0220 - acc: 0.3139 - val_loss: 2.0347 - val_acc: 0.3028\n",
      "Epoch 11/50\n",
      "1080/1080 [==============================] - 42s 39ms/step - loss: 2.0001 - acc: 0.2981 - val_loss: 1.9932 - val_acc: 0.3167\n",
      "Epoch 12/50\n",
      "1080/1080 [==============================] - 38s 35ms/step - loss: 1.9803 - acc: 0.3074 - val_loss: 1.9542 - val_acc: 0.3417\n",
      "Epoch 13/50\n",
      "1080/1080 [==============================] - 39s 36ms/step - loss: 1.9560 - acc: 0.3148 - val_loss: 1.9924 - val_acc: 0.3028\n",
      "Epoch 14/50\n",
      "1080/1080 [==============================] - 35s 33ms/step - loss: 1.9488 - acc: 0.3231 - val_loss: 2.0277 - val_acc: 0.3389\n",
      "Epoch 15/50\n",
      "1080/1080 [==============================] - 40s 37ms/step - loss: 1.9197 - acc: 0.3380 - val_loss: 1.9588 - val_acc: 0.3417\n",
      "Epoch 16/50\n",
      "1080/1080 [==============================] - 39s 36ms/step - loss: 1.9125 - acc: 0.3417 - val_loss: 1.9876 - val_acc: 0.3361\n",
      "Epoch 17/50\n",
      "1080/1080 [==============================] - 43s 40ms/step - loss: 1.8717 - acc: 0.3361 - val_loss: 1.9383 - val_acc: 0.3250\n",
      "Epoch 18/50\n",
      "1080/1080 [==============================] - 37s 35ms/step - loss: 1.8510 - acc: 0.3602 - val_loss: 1.9182 - val_acc: 0.3306\n",
      "Epoch 19/50\n",
      "1080/1080 [==============================] - 36s 34ms/step - loss: 1.8354 - acc: 0.3630 - val_loss: 1.9263 - val_acc: 0.3333\n",
      "Epoch 20/50\n",
      "1080/1080 [==============================] - 37s 34ms/step - loss: 1.8299 - acc: 0.3750 - val_loss: 1.9283 - val_acc: 0.3472\n",
      "Epoch 21/50\n",
      "1080/1080 [==============================] - 32s 30ms/step - loss: 1.7844 - acc: 0.3880 - val_loss: 1.8930 - val_acc: 0.3389\n",
      "Epoch 22/50\n",
      "1080/1080 [==============================] - 31s 28ms/step - loss: 1.7765 - acc: 0.3917 - val_loss: 1.8894 - val_acc: 0.3806\n",
      "Epoch 23/50\n",
      "1080/1080 [==============================] - 31s 28ms/step - loss: 1.7585 - acc: 0.3843 - val_loss: 1.8844 - val_acc: 0.3639\n",
      "Epoch 24/50\n",
      "1080/1080 [==============================] - 30s 28ms/step - loss: 1.7700 - acc: 0.4000 - val_loss: 1.9482 - val_acc: 0.3083\n",
      "Epoch 25/50\n",
      "1080/1080 [==============================] - 30s 28ms/step - loss: 1.7025 - acc: 0.4139 - val_loss: 2.0972 - val_acc: 0.2972\n",
      "Epoch 26/50\n",
      "1080/1080 [==============================] - 32s 29ms/step - loss: 1.7144 - acc: 0.4111 - val_loss: 1.8815 - val_acc: 0.3722\n",
      "Epoch 27/50\n",
      "1080/1080 [==============================] - 30s 28ms/step - loss: 1.6889 - acc: 0.4028 - val_loss: 1.8831 - val_acc: 0.3583\n",
      "Epoch 28/50\n",
      "1080/1080 [==============================] - 37s 35ms/step - loss: 1.6829 - acc: 0.4157 - val_loss: 1.8570 - val_acc: 0.3861\n",
      "Epoch 29/50\n",
      "1080/1080 [==============================] - 31s 29ms/step - loss: 1.6407 - acc: 0.4278 - val_loss: 1.8777 - val_acc: 0.3722\n",
      "Epoch 30/50\n",
      "1080/1080 [==============================] - 30s 28ms/step - loss: 1.6417 - acc: 0.4306 - val_loss: 1.8429 - val_acc: 0.3750\n",
      "Epoch 31/50\n",
      "1080/1080 [==============================] - 32s 29ms/step - loss: 1.6283 - acc: 0.4324 - val_loss: 1.9433 - val_acc: 0.3583\n",
      "Epoch 32/50\n",
      "1080/1080 [==============================] - 3293s 3s/step - loss: 1.5970 - acc: 0.4361 - val_loss: 2.0769 - val_acc: 0.3222\n",
      "Epoch 33/50\n",
      "1080/1080 [==============================] - 928s 859ms/step - loss: 1.6231 - acc: 0.4398 - val_loss: 1.8709 - val_acc: 0.3528\n",
      "Epoch 34/50\n",
      "1080/1080 [==============================] - 35s 32ms/step - loss: 1.5400 - acc: 0.4880 - val_loss: 1.8327 - val_acc: 0.3611\n",
      "Epoch 35/50\n",
      "1080/1080 [==============================] - 31s 29ms/step - loss: 1.5501 - acc: 0.4759 - val_loss: 1.8439 - val_acc: 0.4056\n",
      "Epoch 36/50\n",
      "1080/1080 [==============================] - 31s 29ms/step - loss: 1.5341 - acc: 0.4694 - val_loss: 1.8491 - val_acc: 0.3694\n",
      "Epoch 37/50\n",
      "1080/1080 [==============================] - 40s 37ms/step - loss: 1.5298 - acc: 0.4843 - val_loss: 1.8188 - val_acc: 0.3917\n",
      "Epoch 38/50\n",
      "1080/1080 [==============================] - 39s 36ms/step - loss: 1.4774 - acc: 0.4981 - val_loss: 1.8269 - val_acc: 0.3750\n",
      "Epoch 39/50\n",
      "1080/1080 [==============================] - 37s 34ms/step - loss: 1.4860 - acc: 0.4824 - val_loss: 1.8561 - val_acc: 0.3778\n",
      "Epoch 40/50\n",
      "1080/1080 [==============================] - 38s 36ms/step - loss: 1.4558 - acc: 0.5111 - val_loss: 1.8949 - val_acc: 0.3389\n",
      "Epoch 41/50\n",
      "1080/1080 [==============================] - 39s 36ms/step - loss: 1.4528 - acc: 0.5250 - val_loss: 1.8024 - val_acc: 0.3861\n",
      "Epoch 42/50\n",
      "1080/1080 [==============================] - 37s 34ms/step - loss: 1.4101 - acc: 0.5204 - val_loss: 1.8061 - val_acc: 0.3806\n",
      "Epoch 43/50\n",
      "1080/1080 [==============================] - 37s 34ms/step - loss: 1.3942 - acc: 0.5296 - val_loss: 1.8662 - val_acc: 0.3833\n",
      "Epoch 44/50\n",
      "1080/1080 [==============================] - 39s 36ms/step - loss: 1.3674 - acc: 0.5306 - val_loss: 1.8643 - val_acc: 0.3556\n",
      "Epoch 45/50\n",
      "1080/1080 [==============================] - 37s 34ms/step - loss: 1.3389 - acc: 0.5463 - val_loss: 2.0530 - val_acc: 0.3222\n",
      "Epoch 46/50\n",
      "1080/1080 [==============================] - 39s 36ms/step - loss: 1.3513 - acc: 0.5481 - val_loss: 1.9889 - val_acc: 0.3556\n",
      "Epoch 47/50\n",
      "1080/1080 [==============================] - 39s 36ms/step - loss: 1.3471 - acc: 0.5472 - val_loss: 1.9022 - val_acc: 0.3583\n",
      "Epoch 48/50\n",
      "1080/1080 [==============================] - 35s 33ms/step - loss: 1.3095 - acc: 0.5602 - val_loss: 2.4250 - val_acc: 0.2639\n",
      "Epoch 49/50\n",
      "1080/1080 [==============================] - 37s 35ms/step - loss: 1.3177 - acc: 0.5602 - val_loss: 1.8883 - val_acc: 0.4000\n",
      "Epoch 50/50\n",
      "1080/1080 [==============================] - 34s 31ms/step - loss: 1.2656 - acc: 0.5704 - val_loss: 1.8384 - val_acc: 0.3750\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model_history=model.fit(X_train, y_train,batch_size=16, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 epoch\n",
    "# val_accuracy = .3972 mfcc\n",
    "# val_accuracy = 0.2139 chroma\n",
    "# val_accuracy = 0.0639 mfcc + chroma\n",
    "# 50 epoch - changed random_state\n",
    "# val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_feature(file_name, mfcc, chroma, mel):\n",
    "#     with soundfile.SoundFile(file_name) as sound_file:\n",
    "#         X = sound_file.read(dtype=\"float32\")\n",
    "#         sample_rate=sound_file.samplerate\n",
    "#         if chroma:\n",
    "#             stft=np.abs(librosa.stft(X))\n",
    "#         result=np.array([])\n",
    "#         if mfcc:\n",
    "#             mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "#             result=np.hstack((result, mfccs))\n",
    "#         if chroma:\n",
    "#             chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "#             result=np.hstack((result, chroma))\n",
    "#         if mel:\n",
    "#             mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "#             result=np.hstack((result, mel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_piczak.drop(['esc'],axis=1)\n",
    "Y = df_piczak['esc']\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranfom forest on MFCC features\n",
    "rfc_mfcc = RandomForestClassifier(n_estimators=1000, max_depth=None, min_samples_split=2,n_jobs=-1, random_state=42)\n",
    "rfc_mfcc.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the mean bands to its own feature columns\n",
    "df = pd.concat([audio_df,pd.DataFrame(df['mfcc_feature'].values.tolist())],axis=1)\n",
    "df=df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split between train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['path','labels'],axis=1)\n",
    "                                                    , df.labels\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=22\n",
    "                                                   )\n",
    "\n",
    "# Lets see how the data present itself before normalisation \n",
    "X_train[150:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MLPClassifier(alpha=0.01, batch_size=216,epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#DataFlair - Calculate the accuracy of our model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "#DataFlair - Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split between train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['path','labels'],axis=1)\n",
    "                                                    , df.labels\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=22\n",
    "                                                   )\n",
    "\n",
    "# Lets see how the data present itself before normalisation \n",
    "X_train[150:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "# random forest model creation\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "# predictions\n",
    "rfc_predict = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_cv_score = cross_val_score(rfc, X, y, cv=10, scoring=’roc_auc’)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# number of features at every split\n",
    "max_features = [‘auto’, ‘sqrt’]\n",
    "\n",
    "# max depth\n",
    "max_depth = [int(x) for x in np.linspace(100, 500, num = 11)]\n",
    "max_depth.append(None)\n",
    "# create random grid\n",
    "random_grid = {\n",
    " ‘n_estimators’: n_estimators,\n",
    " ‘max_features’: max_features,\n",
    " ‘max_depth’: max_depth\n",
    " }\n",
    "# Random search of parameters\n",
    "rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the model\n",
    "rfc_random.fit(X_train, y_train)\n",
    "# print results\n",
    "print(rfc_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing data\n",
    "train_data = pd.DataFrame()\n",
    "train_data['fname'] = train['fname']\n",
    "test_data = pd.DataFrame()\n",
    "test_data['fname'] = audio_test_files\n",
    "\n",
    "train_data = train_data['fname'].apply(get_mfcc, path='../input/audio_train/')\n",
    "print('done loading train mfcc')\n",
    "test_data = test_data['fname'].apply(get_mfcc, path='../input/audio_test/')\n",
    "print('done loading test mfcc')\n",
    "\n",
    "train_data['label'] = train['label']\n",
    "test_data['label'] = np.zeros((len(audio_test_files)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
