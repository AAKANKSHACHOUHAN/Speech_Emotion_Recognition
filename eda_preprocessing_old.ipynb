{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "x, sr = librosa.load('/Users/murielkosaka/Desktop/capstone_project/audio/audio_speech_actors_01-24/Actor_01/03-01-01-01-01-01-01.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveplot(x, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Audio(data=x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "single_mfcc = librosa.feature.mfcc(y=x, sr=sr, n_mfcc=13)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(3,1,1)\n",
    "librosa.display.specshow(single_mfcc, x_axis='time')\n",
    "plt.ylabel('MFCC')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole Dataset (1440 files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import glob \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import os # interface with underlying OS that python is running on\n",
    "import sys\n",
    "import warnings\n",
    "# ignore warnings \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "\n",
    "Vocal channel (01 = speech, 02 = song).\n",
    "\n",
    "Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "\n",
    "Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "\n",
    "Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "\n",
    "Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "\n",
    "Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
    "\n",
    "So, here's an example of an audio filename. 02-01-06-01-02-01-12.mp4\n",
    "\n",
    "This means the meta data for the audio file is:\n",
    "\n",
    "Video-only (02)\n",
    "\n",
    "Speech (01)\n",
    "\n",
    "Fearful (06)\n",
    "\n",
    "Normal intensity (01)\n",
    "\n",
    "Statement \"dogs\" (02)\n",
    "\n",
    "1st Repetition (01)\n",
    "\n",
    "12th Actor (12) - Female (as the actor ID number is even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Actor_01', 'Actor_02', 'Actor_03', 'Actor_04', 'Actor_05']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio = \"/Users/murielkosaka/Desktop/capstone_project/audio/audio_speech_actors_01-24/\"\n",
    "\n",
    "actor_folders = os.listdir(audio) #list files in audio directory\n",
    "actor_folders.sort() \n",
    "actor_folders[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio/audio/audio_speech_actors_01-24/Actor_14\n",
    "# 03-01-02-01-02-01-14.wav\n",
    "\n",
    "emotion = []\n",
    "gender = []\n",
    "file_path = []\n",
    "for i in actor_folders:\n",
    "    filename = os.listdir(audio + i) #iterate over Actor folders\n",
    "    for f in filename: # go through files in Actor folder\n",
    "        part = f.split('.')[0].split('-')\n",
    "        emotion.append(int(part[2]))\n",
    "        bg = int(part[6])\n",
    "        if bg%2 == 0:\n",
    "            bg = \"female\"\n",
    "        else:\n",
    "            bg = \"male\"\n",
    "        gender.append(bg)\n",
    "        file_path.append(audio + i + '/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['03-01-03-02-01-02-24.wav',\n",
       " '03-01-03-01-02-02-24.wav',\n",
       " '03-01-02-02-02-01-24.wav',\n",
       " '03-01-02-01-01-01-24.wav',\n",
       " '03-01-01-01-01-02-24.wav',\n",
       " '03-01-06-01-01-02-24.wav',\n",
       " '03-01-05-01-01-01-24.wav',\n",
       " '03-01-05-02-02-01-24.wav',\n",
       " '03-01-06-02-02-02-24.wav',\n",
       " '03-01-04-01-02-02-24.wav',\n",
       " '03-01-07-01-02-01-24.wav',\n",
       " '03-01-07-02-01-01-24.wav',\n",
       " '03-01-04-02-01-02-24.wav',\n",
       " '03-01-08-02-01-01-24.wav',\n",
       " '03-01-08-01-02-01-24.wav',\n",
       " '03-01-05-01-02-02-24.wav',\n",
       " '03-01-06-01-02-01-24.wav',\n",
       " '03-01-06-02-01-01-24.wav',\n",
       " '03-01-05-02-01-02-24.wav',\n",
       " '03-01-07-01-01-02-24.wav',\n",
       " '03-01-04-01-01-01-24.wav',\n",
       " '03-01-04-02-02-01-24.wav',\n",
       " '03-01-07-02-02-02-24.wav',\n",
       " '03-01-08-02-02-02-24.wav',\n",
       " '03-01-08-01-01-02-24.wav',\n",
       " '03-01-03-02-02-01-24.wav',\n",
       " '03-01-03-01-01-01-24.wav',\n",
       " '03-01-02-02-01-02-24.wav',\n",
       " '03-01-01-01-02-01-24.wav',\n",
       " '03-01-02-01-02-02-24.wav',\n",
       " '03-01-04-02-01-01-24.wav',\n",
       " '03-01-07-02-01-02-24.wav',\n",
       " '03-01-07-01-02-02-24.wav',\n",
       " '03-01-04-01-02-01-24.wav',\n",
       " '03-01-06-02-02-01-24.wav',\n",
       " '03-01-05-02-02-02-24.wav',\n",
       " '03-01-05-01-01-02-24.wav',\n",
       " '03-01-06-01-01-01-24.wav',\n",
       " '03-01-08-01-02-02-24.wav',\n",
       " '03-01-08-02-01-02-24.wav',\n",
       " '03-01-01-01-01-01-24.wav',\n",
       " '03-01-02-01-01-02-24.wav',\n",
       " '03-01-02-02-02-02-24.wav',\n",
       " '03-01-03-01-02-01-24.wav',\n",
       " '03-01-03-02-01-01-24.wav',\n",
       " '03-01-02-01-02-01-24.wav',\n",
       " '03-01-01-01-02-02-24.wav',\n",
       " '03-01-02-02-01-01-24.wav',\n",
       " '03-01-03-01-01-02-24.wav',\n",
       " '03-01-03-02-02-02-24.wav',\n",
       " '03-01-07-02-02-01-24.wav',\n",
       " '03-01-04-02-02-02-24.wav',\n",
       " '03-01-04-01-01-02-24.wav',\n",
       " '03-01-07-01-01-01-24.wav',\n",
       " '03-01-05-02-01-01-24.wav',\n",
       " '03-01-06-02-01-02-24.wav',\n",
       " '03-01-06-01-02-02-24.wav',\n",
       " '03-01-05-01-02-01-24.wav',\n",
       " '03-01-08-01-01-01-24.wav',\n",
       " '03-01-08-02-02-01-24.wav']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(audio + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>emotion</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>surprise</td>\n",
       "      <td>/Users/murielkosaka/Desktop/capstone_project/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>surprise</td>\n",
       "      <td>/Users/murielkosaka/Desktop/capstone_project/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>angry</td>\n",
       "      <td>/Users/murielkosaka/Desktop/capstone_project/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>fear</td>\n",
       "      <td>/Users/murielkosaka/Desktop/capstone_project/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>fear</td>\n",
       "      <td>/Users/murielkosaka/Desktop/capstone_project/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>female</td>\n",
       "      <td>fear</td>\n",
       "      <td>/Users/murielkosaka/Desktop/capstone_project/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>female</td>\n",
       "      <td>fear</td>\n",
       "      <td>/Users/murielkosaka/Desktop/capstone_project/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>female</td>\n",
       "      <td>angry</td>\n",
       "      <td>/Users/murielkosaka/Desktop/capstone_project/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>female</td>\n",
       "      <td>surprise</td>\n",
       "      <td>/Users/murielkosaka/Desktop/capstone_project/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>female</td>\n",
       "      <td>surprise</td>\n",
       "      <td>/Users/murielkosaka/Desktop/capstone_project/a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   emotion                                               path\n",
       "0       male  surprise  /Users/murielkosaka/Desktop/capstone_project/a...\n",
       "1       male  surprise  /Users/murielkosaka/Desktop/capstone_project/a...\n",
       "2       male     angry  /Users/murielkosaka/Desktop/capstone_project/a...\n",
       "3       male      fear  /Users/murielkosaka/Desktop/capstone_project/a...\n",
       "4       male      fear  /Users/murielkosaka/Desktop/capstone_project/a...\n",
       "...      ...       ...                                                ...\n",
       "1435  female      fear  /Users/murielkosaka/Desktop/capstone_project/a...\n",
       "1436  female      fear  /Users/murielkosaka/Desktop/capstone_project/a...\n",
       "1437  female     angry  /Users/murielkosaka/Desktop/capstone_project/a...\n",
       "1438  female  surprise  /Users/murielkosaka/Desktop/capstone_project/a...\n",
       "1439  female  surprise  /Users/murielkosaka/Desktop/capstone_project/a...\n",
       "\n",
       "[1440 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_df = pd.DataFrame(emotion)\n",
    "audio_df = audio_df.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\n",
    "audio_df\n",
    "audio_df = pd.concat([pd.DataFrame(gender),audio_df],axis=1)\n",
    "audio_df.columns = ['gender','emotion']\n",
    "# audio_df['labels'] =audio_df.gender + '_' + audio_df.emotion\n",
    "audio_df = pd.concat([audio_df,pd.DataFrame(file_path, columns = ['path'])],axis=1)\n",
    "# audio_df = audio_df.drop(['gender', 'emotion'], axis=1)\n",
    "# audio_df.labels.value_counts()\n",
    "audio_df\n",
    "\n",
    "# audio_df = pd.DataFrame(emotion)\n",
    "# audio_df = audio_df.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\n",
    "# audio_df = pd.concat([pd.DataFrame(gender),audio_df],axis=1)\n",
    "# audio_df.columns = ['gender','emotion']\n",
    "# audio_df['labels'] =audio_df.gender + '_' + audio_df.emotion\n",
    "# audio_df = pd.concat([audio_df,pd.DataFrame(file_path, columns = ['path'])],axis=1)\n",
    "# audio_df = audio_df.drop(['gender', 'emotion'], axis=1)\n",
    "# audio_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df.drop(columns='gender',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df.to_csv('audio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.listdir(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fname = audio + 'Actor_02/03-01-01-01-01-01-02.wav'  #female neutral\n",
    "data_neutral, sr_neutral = librosa.load(fname)\n",
    "plt.figure(figsize=(10, 5))\n",
    "librosa.display.waveplot(data_neutral, sr=sr_neutral)\n",
    "ipd.Audio(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fname = audio + 'Actor_02/03-01-02-01-01-01-02.wav'  #female calm\n",
    "data, sampling_rate = librosa.load(fname)\n",
    "plt.figure(figsize=(10, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)\n",
    "ipd.Audio(fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC\n",
    "### The mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features (usually about 10–20) which concisely describe the overall shape of a spectral envelope. MFCC is a good \"representation\" of the vocal tract that produces the sound. Think of it like an x-ray of your mouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_mfcc = librosa.feature.mfcc(y=data_neutral, sr=sr_neutral, n_mfcc=13)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(3,1,1)\n",
    "librosa.display.specshow(fa_mfcc, x_axis='time')\n",
    "plt.ylabel('MFCC')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCC\n",
    "#The mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features \n",
    "#(usually about 10–20) which concisely describe the overall shape of a spectral envelope.\n",
    "# good \"representation\" of the vocal tract that produces the sound. Think of it like an \n",
    "# x-ray of your mouth\n",
    "mfcc = librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=13)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(3,1,1)\n",
    "librosa.display.specshow(mfcc, x_axis='time')\n",
    "plt.ylabel('MFCC')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male surprised\n",
    "pathh = audio + 'Actor_09/03-01-08-02-02-02-09.wav'\n",
    "X, sample_rate = librosa.load(pathh, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "male = librosa.feature.spectral_centroid(y=X, sr=sample_rate)\n",
    "male = np.mean(librosa.feature.spectral_centroid(y=X, sr=sample_rate), axis=0)\n",
    "print(len(male))\n",
    "\n",
    "# Female surprised\n",
    "path= audio + 'Actor_08/03-01-08-02-02-02-08.wav'\n",
    "X, sample_rate = librosa.load(path,duration=2.5,sr=22050*2,offset=0.5)\n",
    "female = librosa.feature.spectral_centroid(y=X, sr=sample_rate)\n",
    "female = np.mean(librosa.feature.spectral_centroid(y=X, sr=sample_rate), axis=0)\n",
    "print(len(female))\n",
    "\n",
    "# Male happy\n",
    "pathh = audio + 'Actor_09/03-01-03-02-02-02-09.wav'\n",
    "X, sample_rate = librosa.load(pathh, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "male1 = librosa.feature.spectral_centroid(y=X, sr=sample_rate)\n",
    "male1 = np.mean(librosa.feature.spectral_centroid(y=X, sr=sample_rate), axis=0)\n",
    "print(len(male1))\n",
    "\n",
    "# Female happy\n",
    "path= audio + 'Actor_08/03-01-03-02-02-02-08.wav'\n",
    "X, sample_rate = librosa.load(path,duration=2.5,sr=22050*2,offset=0.5)\n",
    "female1 = librosa.feature.spectral_centroid(y=X, sr=sample_rate)\n",
    "female1 = np.mean(librosa.feature.spectral_centroid(y=X, sr=sample_rate), axis=0)\n",
    "print(len(female1))\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(female, label='Female Surprised')\n",
    "plt.plot(male, label='Male Surprised')\n",
    "plt.plot(female1, label='Female happy')\n",
    "plt.plot(male1, label='Male happy')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male surprised\n",
    "pathh = audio + 'Actor_09/03-01-08-02-02-02-09.wav'\n",
    "X, sample_rate = librosa.load(pathh, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "male = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
    "male = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13), axis=0)\n",
    "print(len(male))\n",
    "\n",
    "# Female surprised\n",
    "path= audio + 'Actor_08/03-01-08-02-02-02-08.wav'\n",
    "X, sample_rate = librosa.load(path,duration=2.5,sr=22050*2,offset=0.5)\n",
    "female = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
    "female = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13), axis=0)\n",
    "print(len(female))\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(female, label='Female Surprised')\n",
    "plt.plot(male, label='Male Surprised')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogram - how the audio spectrum varies as a function of time\n",
    "spectrogram = librosa.feature.melspectrogram(y=X, sr=sampling_rate)\n",
    "db_spec = librosa.power_to_db(spectrogram, ref=np.max,)\n",
    "librosa.display.specshow(db_spec,y_axis='mel', x_axis='time', sr=sampling_rate)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_spec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-71.20022, -71.20022, -71.20022, -71.20022, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-70.46105, -70.46105, -70.46105, -70.46105, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-64.17679, -64.39374, -64.444954, -64.26804, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-73.2803, -73.2803, -73.2803, -73.2803, -73.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-44.965843, -44.467876, -44.512608, -44.93480...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            log_spec\n",
       "0  [-71.20022, -71.20022, -71.20022, -71.20022, -...\n",
       "1  [-70.46105, -70.46105, -70.46105, -70.46105, -...\n",
       "2  [-64.17679, -64.39374, -64.444954, -64.26804, ...\n",
       "3  [-73.2803, -73.2803, -73.2803, -73.2803, -73.2...\n",
       "4  [-44.965843, -44.467876, -44.512608, -44.93480..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['log_spec'])\n",
    "\n",
    "counter=0\n",
    "\n",
    "for index,path in enumerate(audio_df.path):\n",
    "    #get wave representation\n",
    "    X, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=3,sr=44100,offset=0.5)\n",
    "        \n",
    "#     #Mel-frequency cepstral coefficients (MFCCs)\n",
    "#     mfcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
    "#     #temporal averaging\n",
    "#     mfcc=np.mean(mfcc,axis=0)\n",
    "    \n",
    "    #get the mel-scaled spectrogram (ransform both the y-axis (frequency) to log scale, and the “color” axis (amplitude) to Decibels, which is kinda the log scale of amplitudes.)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=X, sr=sample_rate, n_mels=128,fmax=8000) \n",
    "    db_spec = librosa.power_to_db(spectrogram)\n",
    "    #temporally average spectrogram\n",
    "    log_spectrogram = np.mean(db_spec, axis = 0)\n",
    "    \n",
    "#     #compute chroma energy (pertains to 12 different pitch classes)\n",
    "#     chroma = librosa.feature.chroma_stft(y=X, sr=sample_rate)\n",
    "#     #temporally average chroma\n",
    "#     chroma = np.mean(chroma, axis = 0)\n",
    "    \n",
    "    # #compute spectral contrast\n",
    "    # contrast = librosa.feature.spectral_contrast(y=X, sr=sample_rate)\n",
    "    # contrast = np.mean(contrast, axis= 0)\n",
    "\n",
    "    # compute zero-crossing-rate (zcr:the zcr is the rate of sign changes along a signal i.e.m the rate at \n",
    "    # which the signal changes from positive to negative or back - separation of voiced andunvoiced speech.)\n",
    "    # zcr = librosa.feature.zero_crossing_rate(y=X)\n",
    "    # zcr = np.mean(zcr, axis= 0)\n",
    "    \n",
    "    df.loc[counter] = [log_spectrogram]\n",
    "    counter=counter+1   \n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_feature(file_name, mfcc, chroma, mel):\n",
    "#     with soundfile.SoundFile(file_name) as sound_file:\n",
    "#         X = sound_file.read(dtype=\"float32\")\n",
    "#         sample_rate=sound_file.samplerate\n",
    "#         if chroma:\n",
    "#             stft=np.abs(librosa.stft(X))\n",
    "#         result=np.array([])\n",
    "#         if mfcc:\n",
    "#             mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "#             result=np.hstack((result, mfccs))\n",
    "#         if chroma:\n",
    "#             chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "#             result=np.hstack((result, chroma))\n",
    "#         if mel:\n",
    "#             mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "#             result=np.hstack((result, mel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Dense, Embedding, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET MEANS TO THEIR OWN COLUMNS\n",
    "df_combined = pd.concat([audio_df,pd.DataFrame(df['log_spec'].values.tolist()),\n",
    "#                          pd.DataFrame(df['chroma_feat'].values.tolist()),\n",
    "#                          pd.DataFrame(df['spec_feat'].values.tolist())\n",
    "                         ],axis=1)\n",
    "df_combined = df_combined.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.drop(columns='path',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions=df_combined.emotion\n",
    "emotions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SET MEANS TO THEIR OWN COLUMNS\n",
    "\n",
    "df_combined = pd.concat([audio_df,pd.DataFrame(df['mfcc_feature'].values.tolist()),pd.DataFrame(df_chroma['chroma_feat'].values.tolist())],axis=1)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SET MEANS TO THEIR OWN COLUMNS\n",
    "df = pd.concat([audio_df,pd.DataFrame(df['mfcc_feature'].values.tolist())],axis=1)\n",
    "df=df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TRAIN TEST SPLIT\n",
    "X_model, X_test, y_model, y_test = train_test_split(df_combined.drop(['path','emotion'],axis=1)\n",
    "                                                    , df_combined.emotion\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=42\n",
    "                                                   )\n",
    "# TRAIN TEST SPLIT\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_model\n",
    "                                                    , y_model\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=42\n",
    "                                                   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE DATA\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std\n",
    "X_validation = (X_validation - mean) / std\n",
    "\n",
    "\n",
    "# Check the dataset now \n",
    "# X_train[150:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TURN DATA INTO ARRAYS FOR KERAS\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "X_validation=np.array(X_validation)\n",
    "y_validation=np.array(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE HOT ENCODE THE TARGET\n",
    "# CNN REQUIRES INPUT AND OUTPUT ARE NUMBERS\n",
    "lb = LabelEncoder()\n",
    "y_train = to_categorical(lb.fit_transform(y_train))\n",
    "y_test = to_categorical(lb.fit_transform(y_test))\n",
    "y_validation = to_categorical(lb.fit_transform(y_validation))\n",
    "\n",
    "\n",
    "print(y_validation[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time series data requires kernel sliding in only one dimension and have spatial properties: 1d CNN\n",
    "# reshape data to 3d tensor\n",
    "X_train = X_train[:,:,np.newaxis]\n",
    "X_test = X_test[:,:,np.newaxis]\n",
    "X_validation = X_validation[:,:,np.newaxis]\n",
    "\n",
    "X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.optimizers import SGD\n",
    "from keras.constraints import max_norm\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "# acc-51,test acc-48\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, kernel_size=(10), activation='relu', input_shape=(X_train.shape[1],1)))\n",
    "model.add(Conv1D(128, kernel_size=(10),activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(128, kernel_size=(10),activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(Conv1D(256, kernel_size=(4), activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "model.summary()\n",
    "opt = keras.optimizers.Adam(lr=0.0001)\n",
    "\n",
    "# #acc-61,test acc-54\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(64, kernel_size=(8), activation='relu', input_shape=(X_train.shape[1],1)))\n",
    "# model.add(Conv1D(128, kernel_size=(8),activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=(8)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Conv1D(128, kernel_size=(8),activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling1D(pool_size=(8)))\n",
    "# model.add(Dropout(0.2))\n",
    "# # model.add(Conv1D(256, kernel_size=(4), activation='relu'))\n",
    "# # model.add(MaxPooling1D(pool_size=(2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(8, activation='softmax'))\n",
    "# model.summary()\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n",
    "\n",
    "# acc-82, test acc-49\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(64, kernel_size=(8), activation='relu', input_shape=(X_train.shape[1],1)))\n",
    "# model.add(Conv1D(64, kernel_size=(8),activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=(4)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Conv1D(128, kernel_size=(8),activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling1D(pool_size=(4)))\n",
    "# model.add(Dropout(0.2))\n",
    "# # model.add(Conv1D(256, kernel_size=(4), activation='relu'))\n",
    "# # model.add(MaxPooling1D(pool_size=(2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(8, activation='softmax'))\n",
    "# model.summary()\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n",
    "\n",
    "\n",
    "#BUILD CNN MODEL (even accuracy scores)\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(32, kernel_size=(8), activation='relu', input_shape=(X_train.shape[1],1)))\n",
    "# model.add(Conv1D(64, kernel_size=(8),activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=(4)))\n",
    "# model.add(Dropout(0.4))\n",
    "# model.add(Conv1D(128, kernel_size=(8),activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling1D(pool_size=(4)))\n",
    "# model.add(Dropout(0.4))\n",
    "# # model.add(Conv1D(256, kernel_size=(4), activation='relu'))\n",
    "# # model.add(MaxPooling1D(pool_size=(2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(8, activation='softmax'))\n",
    "# model.summary()\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "cb = ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True)\n",
    "# FIT MODEL\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model_history=model.fit(X_train, y_train,batch_size=32, epochs=50, validation_data=(X_validation, y_validation),callbacks=[cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Loss of the model is - \" , model.evaluate(X_test,y_test)[0])\n",
    "print(\"Accuracy of the model is - \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_history.history['acc'])\n",
    "plt.plot(model_history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test, batch_size=32)\n",
    "predictions=predictions.argmax(axis=1)\n",
    "actual=y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(actual, predictions)\n",
    "plt.figure(figsize = (12, 10))\n",
    "cm = pd.DataFrame(cm , index = [i for i in lb.classes_] , columns = [i for i in lb.classes_])\n",
    "ax = sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.title('Confusion Matrix', size=20)\n",
    "plt.xlabel('Predicted Labels', size=14)\n",
    "plt.ylabel('Actual Labels', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# predictions \n",
    "predictions = model.predict(X_test, batch_size=32)\n",
    "predictions=predictions.argmax(axis=1)\n",
    "predictions\n",
    "predictions = predictions.astype(int).flatten()\n",
    "predictions = (lb.inverse_transform((predictions)))\n",
    "predictions = pd.DataFrame({'Predicted Values': predictions})\n",
    "\n",
    "# Actual labels\n",
    "actual=y_test.argmax(axis=1)\n",
    "actual = actual.astype(int).flatten()\n",
    "actual = (lb.inverse_transform((actual)))\n",
    "actual = pd.DataFrame({'Actual Values': actual})\n",
    "\n",
    "# Lets combined both of them into a single dataframe\n",
    "finaldf = actual.join(predictions)\n",
    "finaldf[140:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['acc'])\n",
    "plt.plot(model_history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "hf = h5py.File('best_model.h5', 'r')\n",
    "hf.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST SPLIT\n",
    "X_model, X_test, y_model, y_test = train_test_split(combined_df.drop(['path','emotion'],axis=1)\n",
    "                                                    , combined_df.emotion\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=False\n",
    "                                                    , random_state=42\n",
    "                                                   )\n",
    "# TRAIN TEST SPLIT\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_model\n",
    "                                                    , y_model\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=False\n",
    "                                                    , random_state=42\n",
    "                                                   )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE DATA\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std\n",
    "X_validation = (X_validation - mean) / std\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TURN DATA INTO ARRAYS FOR KERAS\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "X_validation=np.array(X_validation)\n",
    "y_validation=np.array(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(810, 259, 1)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#time series data requires kernel sliding in only one dimension and have spatial properties: 1d CNN\n",
    "# reshape data to 3d tensor\n",
    "X_train = X_train[:,:,np.newaxis]\n",
    "X_test = X_test[:,:,np.newaxis]\n",
    "X_validation = X_validation[:,:,np.newaxis]\n",
    "\n",
    "X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def make_classifier(optimizer='adam'):\n",
    "    #BUILD CNN MODEL\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=(10), activation='relu', input_shape=(X_train.shape[1],1)))\n",
    "    model.add(Conv1D(64, kernel_size=(10),activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(MaxPooling1D(pool_size=(8)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv1D(128, kernel_size=(10),activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=(8)))\n",
    "    model.add(Dropout(0.25))\n",
    "# model.add(Conv1D(256, kernel_size=(4), activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 45s 23ms/step - loss: 2.0502 - acc: 0.2526\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 21s 11ms/step - loss: 2.0137 - acc: 0.2423\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 17s 9ms/step - loss: 2.0027 - acc: 0.2587\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 17s 9ms/step - loss: 2.0234 - acc: 0.2551\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 18s 9ms/step - loss: 2.0135 - acc: 0.2562\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 17s 9ms/step - loss: 2.0396 - acc: 0.2325\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 17s 9ms/step - loss: 2.0227 - acc: 0.2623\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 17s 9ms/step - loss: 2.0041 - acc: 0.2515\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 18s 9ms/step - loss: 2.0187 - acc: 0.2505\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 19s 10ms/step - loss: 2.0146 - acc: 0.2572\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 19s 10ms/step - loss: 2.0434 - acc: 0.2449\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 18s 9ms/step - loss: 2.0365 - acc: 0.2459\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 17s 9ms/step - loss: 2.0148 - acc: 0.2557\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 17s 9ms/step - loss: 2.0423 - acc: 0.2526\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 17s 9ms/step - loss: 2.0525 - acc: 0.2464\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 18s 9ms/step - loss: 2.0275 - acc: 0.2557\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 19s 10ms/step - loss: 2.0136 - acc: 0.2464\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 23s 12ms/step - loss: 2.0283 - acc: 0.2521\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 20s 11ms/step - loss: 2.0234 - acc: 0.2649\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 20s 10ms/step - loss: 2.0301 - acc: 0.2531\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 21s 11ms/step - loss: 2.0212 - acc: 0.2526\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 20s 10ms/step - loss: 2.0362 - acc: 0.2495 3s - loss: 2.0631 - \n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 19s 10ms/step - loss: 2.0275 - acc: 0.2464\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 20s 10ms/step - loss: 2.0196 - acc: 0.2613\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 19s 10ms/step - loss: 2.0167 - acc: 0.2541\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 19s 10ms/step - loss: 2.0162 - acc: 0.2659\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 20s 10ms/step - loss: 2.0324 - acc: 0.2407\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 19s 10ms/step - loss: 2.0453 - acc: 0.2438\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 24s 12ms/step - loss: 2.0286 - acc: 0.2423\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 22s 12ms/step - loss: 2.0312 - acc: 0.2551\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 22s 11ms/step - loss: 2.0920 - acc: 0.2479\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 19s 10ms/step - loss: 2.0785 - acc: 0.2361\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 19s 10ms/step - loss: 2.0743 - acc: 0.2541\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 21s 11ms/step - loss: 2.0992 - acc: 0.2443\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 22s 11ms/step - loss: 2.0796 - acc: 0.2598\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 23s 12ms/step - loss: 2.1149 - acc: 0.2248\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 22s 11ms/step - loss: 2.0798 - acc: 0.2299\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 20s 10ms/step - loss: 2.0975 - acc: 0.2361\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 27s 14ms/step - loss: 2.0893 - acc: 0.2577\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 21s 11ms/step - loss: 2.0889 - acc: 0.2454\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 21s 11ms/step - loss: 2.1160 - acc: 0.2377\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 26s 13ms/step - loss: 2.1016 - acc: 0.2546\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 24s 12ms/step - loss: 2.0893 - acc: 0.2407\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 22s 11ms/step - loss: 2.1031 - acc: 0.2567\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 22s 11ms/step - loss: 2.0768 - acc: 0.2747\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 23s 12ms/step - loss: 2.1036 - acc: 0.2299\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 22s 11ms/step - loss: 2.0795 - acc: 0.2485\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 23s 12ms/step - loss: 2.0730 - acc: 0.2531\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 24s 12ms/step - loss: 2.0573 - acc: 0.2659\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 24s 12ms/step - loss: 2.0721 - acc: 0.2814\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 23s 12ms/step - loss: 2.1042 - acc: 0.2356\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 21s 11ms/step - loss: 2.0947 - acc: 0.2443\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 24s 12ms/step - loss: 2.0891 - acc: 0.2464\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 24s 12ms/step - loss: 2.0958 - acc: 0.2397\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 24s 12ms/step - loss: 2.0895 - acc: 0.2639\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 23s 12ms/step - loss: 2.0886 - acc: 0.2356\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 24s 13ms/step - loss: 2.0972 - acc: 0.2289\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 2.0976 - acc: 0.2459\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 24s 12ms/step - loss: 2.0860 - acc: 0.2598\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 23s 12ms/step - loss: 2.0952 - acc: 0.2562\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 23s 12ms/step - loss: 2.1508 - acc: 0.2253\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 2.1336 - acc: 0.2423\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 23s 12ms/step - loss: 2.1270 - acc: 0.2567\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 2.1297 - acc: 0.2402\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 2.1275 - acc: 0.2541\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 29s 15ms/step - loss: 2.1457 - acc: 0.2248\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 2.1254 - acc: 0.2402\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 2.1544 - acc: 0.2289\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 24s 13ms/step - loss: 2.1324 - acc: 0.2582\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 28s 14ms/step - loss: 2.1127 - acc: 0.2546\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 2.1235 - acc: 0.2469\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 25s 13ms/step - loss: 2.1358 - acc: 0.2279\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 54s 28ms/step - loss: 2.1382 - acc: 0.2258\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 69s 35ms/step - loss: 2.1207 - acc: 0.2546\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 58s 30ms/step - loss: 2.1309 - acc: 0.2449\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 86s 44ms/step - loss: 2.1360 - acc: 0.2310\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 104s 54ms/step - loss: 2.1454 - acc: 0.2263\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 80s 41ms/step - loss: 2.1393 - acc: 0.2233\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 80s 41ms/step - loss: 2.1388 - acc: 0.2515\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 82s 42ms/step - loss: 2.1150 - acc: 0.2392\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 30s 15ms/step - loss: 2.1430 - acc: 0.2310\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 31s 16ms/step - loss: 2.1731 - acc: 0.2289\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 30s 16ms/step - loss: 2.1243 - acc: 0.2387\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1860/1944 [===========================>..] - ETA: 1s - loss: 2.1300 - acc: 0.2505"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-7ddd76687370>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                            cv=5)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 715\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn = make_classifier)\n",
    "params = {\n",
    "    'batch_size': [10, 20, 30],\n",
    "    'nb_epoch': [50, 100, 150],\n",
    "    'optimizer':['adam','SGD']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=classifier,\n",
    "                           param_grid=params,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5)\n",
    "\n",
    "grid_search = grid_search.fit(X_train,y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "for params, mean_score, scores in grid_result.grid_scores_:\n",
    "    print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))\n",
    "# best_param = grid_search.best_params_\n",
    "# best_accuracy = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_param' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-40605b8e917a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbest_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_param' is not defined"
     ]
    }
   ],
   "source": [
    "print (best_param)\n",
    "print (best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
